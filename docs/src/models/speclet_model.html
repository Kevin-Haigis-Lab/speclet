<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>src.models.speclet_model API documentation</title>
<meta name="description" content="Base class to contain a PyMC3 model." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.models.speclet_model</code></h1>
</header>
<section id="section-intro">
<p>Base class to contain a PyMC3 model.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Base class to contain a PyMC3 model.&#34;&#34;&#34;

from abc import abstractmethod
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import arviz as az
import numpy as np
import pandas as pd
import pymc3 as pm
from pydantic import BaseModel
from theano.tensor.sharedvar import TensorSharedVariable as TTShared

import src.modeling.simulation_based_calibration_helpers as sbc
from src.exceptions import CacheDoesNotExistError
from src.loggers import logger
from src.managers.model_cache_managers import Pymc3ModelCacheManager
from src.managers.model_data_managers import DataManager
from src.modeling import pymc3_sampling_api as pmapi
from src.project_enums import MockDataSize, ModelFitMethod, assert_never

ReplacementsDict = Dict[TTShared, Union[pm.Minibatch, np.ndarray]]


class UnableToLocateNamedVariable(Exception):
    &#34;&#34;&#34;Error when a named variable or object cannot be located.&#34;&#34;&#34;

    pass


class SharedVariableDictionaryNotSet(AttributeError):
    &#34;&#34;&#34;Error for when the shared variable dictionary should be available but is not.&#34;&#34;&#34;

    pass


class PyMC3SamplingParameters(BaseModel):
    &#34;&#34;&#34;Paramerers common to fitting a model in PyMC3.&#34;&#34;&#34;

    draws: int = 1000
    prior_pred_samples: int = 1000
    post_pred_samples: int = 1000


class MCMCSamplingParameters(PyMC3SamplingParameters):
    &#34;&#34;&#34;Parameters for MCMC sampling.&#34;&#34;&#34;

    tune: int = 2000
    cores: int = 4
    chains: int = 4
    init: str = &#34;auto&#34;
    n_init: int = 200000
    target_accept: float = 0.8  # default for pm.NUTS


class VISamplingParameters(PyMC3SamplingParameters):
    &#34;&#34;&#34;Parameters for fitting by VI.&#34;&#34;&#34;

    method: str = &#34;advi&#34;
    n_iterations: int = 50000


class SpecletModel:
    &#34;&#34;&#34;Base class to contain a PyMC3 model.&#34;&#34;&#34;

    name: str
    _debug: bool
    cache_manager: Pymc3ModelCacheManager
    data_manager: DataManager

    model: Optional[pm.Model] = None
    observed_var_name: Optional[str] = None
    shared_vars: Optional[Dict[str, TTShared]] = None
    advi_results: Optional[Tuple[az.InferenceData, pm.Approximation]] = None
    mcmc_results: Optional[az.InferenceData] = None

    mcmc_sampling_params: MCMCSamplingParameters = MCMCSamplingParameters()
    advi_sampling_params: VISamplingParameters = VISamplingParameters()

    def __init__(
        self,
        name: str,
        data_manager: DataManager,
        root_cache_dir: Optional[Path] = None,
        debug: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;Instantiate a Speclet Model.

        Args:
            name (str): Name of the model.
            root_cache_dir (Optional[Path], optional): Location for the cache directory.
              If None (default), then the project&#39;s default cache directory is used.
              Defaults to None.
            debug (bool, optional): Use debug mode? Defaults to False.
            data_manager (Optional[DataManager], optional): Object that will manage the
              data. Defaults to None.
        &#34;&#34;&#34;
        self.name = name
        self._debug = debug
        self.cache_manager = Pymc3ModelCacheManager(
            name=name, root_cache_dir=root_cache_dir
        )
        self.data_manager = data_manager
        self.data_manager.debug = self._debug

    def __str__(self) -&gt; str:
        &#34;&#34;&#34;Describe the object.

        Returns:
            str: String description of the object.
        &#34;&#34;&#34;
        msg = f&#34;Speclet Model: &#39;{self.name}&#39;&#34;
        if self.debug:
            msg += &#34; (debug)&#34;
        return msg

    @property
    def debug(self) -&gt; bool:
        &#34;&#34;&#34;Whether or not to use debug mode.

        Returns:
            bool: The current value for debug mode.
        &#34;&#34;&#34;
        return self._debug

    @debug.setter
    def debug(self, new_value: bool) -&gt; None:
        &#34;&#34;&#34;Set the value for debug mode.

        This also changes the debug mode for the data manager. Changes are only made if
        the new value is different from the current value.

        Args:
            new_value (bool): New value for `debug`.
        &#34;&#34;&#34;
        if new_value == self._debug:
            return
        logger.info(f&#34;Changing value of debug to &#39;{new_value}&#39;.&#34;)
        self._debug = new_value
        if self.data_manager is not None:
            self.data_manager.debug = new_value

    def _reset_model_and_results(self, clear_cache: bool = False):
        logger.warning(&#34;Reseting all model and results.&#34;)
        self.model = None
        self.mcmc_results = None
        self.advi_results = None
        if clear_cache:
            self.clear_cache()

    def clear_cache(self):
        &#34;&#34;&#34;Clear all available caches for the model.&#34;&#34;&#34;
        self.cache_manager.clear_all_caches()

    @abstractmethod
    def model_specification(self) -&gt; Tuple[pm.Model, str]:
        &#34;&#34;&#34;Define the PyMC3 model.

        This model must be overridden by an subclass to define the desired PyMC3 model.

        Returns:
            pm.Model: The PyMC3 model.
            str: Name of the target variable in the model.
        &#34;&#34;&#34;
        raise Exception(
            &#34;The `model_specification()` method must be overridden by subclasses.&#34;
        )

    def build_model(self) -&gt; None:
        &#34;&#34;&#34;Build the PyMC3 model.

        Raises:
            AttributeError: Raised if there is no data manager.
            AttributeError: Raised the `model` attribute is still None after calling
              `self.model_specification()`
            AttributeError: Raised the `observed_var_name` attribute is still None
              after calling `self.model_specification()`
        &#34;&#34;&#34;
        logger.debug(&#34;Building PyMC3 model.&#34;)

        logger.info(&#34;Calling `model_specification()` method.&#34;)
        self.model, self.observed_var_name = self.model_specification()

        if self.model is None:
            m = &#34;The `model` attribute cannot be None at the end of the &#34;
            m += &#34;`build_model()` method.&#34;
            logger.error(m)
            raise AttributeError(m)

        if self.observed_var_name is None:
            m = &#34;The `observed_var_name` attribute cannot be None at the end of the &#34;
            m += &#34;`build_model()` method.&#34;
            logger.error(m)
            raise AttributeError(m)

        return None

    def update_mcmc_sampling_parameters(self) -&gt; None:
        &#34;&#34;&#34;Override if MCMC sampling parameters need to be adjusted.&#34;&#34;&#34;
        return None

    def mcmc_sample_model(
        self,
        draws: Optional[int] = None,
        tune: Optional[int] = None,
        chains: Optional[int] = None,
        cores: Optional[int] = None,
        target_accept: Optional[float] = None,
        prior_pred_samples: Optional[int] = None,
        post_pred_samples: Optional[int] = None,
        random_seed: Optional[int] = None,
        sample_kwargs: Optional[Dict[str, Any]] = None,
        ignore_cache: bool = False,
    ) -&gt; az.InferenceData:
        &#34;&#34;&#34;MCMC sample the model.

        This method primarily wraps the `pymc3_sampling_api.pymc3_sampling_procedure()`
        function.

        Many of the key arguments default to None in the function call, but are replaced
        by the values in the `self.mcmc_sampling_params` attribute.

        Args:
            mcmc_draws (Optional[int], optional): Number of MCMC draws. Defaults to
              None.
            tune (Optional[int], optional): Number of tuning steps. Defaults to None.
            chains (Optional[int], optional): Number of chains. Defaults to 3.
            cores (Optional[int], optional): Number of cores. Defaults to
              None.
            target_accept (Optional[float], optional): MCMC target acceptance. Defaults
              to None.
            prior_pred_samples (Optional[int], optional): Number of samples from the
              prior distributions. Defaults to None.
            post_pred_samples (Optional[int], optional): Number of samples for posterior
              predictions.
            Defaults to None.
            random_seed (Optional[int], optional): The random seed for sampling.
            Defaults to None.
            sample_kwargs (Dict[str, Any], optional): Kwargs for the sampling method.
            Defaults to {}.
            ignore_cache (bool, optional): Should any cached results be ignored?
              Defaults to False.

        Raises:
            AttributeError: Raised if the PyMC3 model does not yet exist.

        Returns:
            az.InferenceData: The results of MCMC sampling.
        &#34;&#34;&#34;
        logger.debug(&#34;Beginning MCMC sampling method.&#34;)
        self.update_mcmc_sampling_parameters()
        if draws is None:
            draws = self.mcmc_sampling_params.draws
        if tune is None:
            tune = self.mcmc_sampling_params.tune
        if chains is None:
            chains = self.mcmc_sampling_params.chains
        if cores is None:
            cores = self.mcmc_sampling_params.cores
        if target_accept is None:
            target_accept = self.mcmc_sampling_params.target_accept
        if prior_pred_samples is None:
            prior_pred_samples = self.mcmc_sampling_params.prior_pred_samples
        if post_pred_samples is None:
            post_pred_samples = self.mcmc_sampling_params.post_pred_samples

        if self.model is None:
            raise AttributeError(
                &#34;Cannot sample: model is &#39;None&#39;. &#34;
                + &#34;Make sure to run `model.build_model()` first.&#34;
            )

        if self.mcmc_results is not None:
            logger.info(&#34;Returning results from stored `mcmc_results` attribute.&#34;)
            return self.mcmc_results

        if not ignore_cache and self.cache_manager.mcmc_cache_exists():
            logger.info(&#34;Returning results from cache.&#34;)
            self.mcmc_results = self.cache_manager.get_mcmc_cache()
            return self.mcmc_results

        if sample_kwargs is None:
            sample_kwargs = {}
        sample_kwargs[&#34;target_accept&#34;] = target_accept

        logger.info(&#34;Beginning MCMC sampling.&#34;)
        _mcmc_results = pmapi.pymc3_sampling_procedure(
            model=self.model,
            mcmc_draws=draws,
            tune=tune,
            chains=chains,
            cores=cores,
            prior_pred_samples=prior_pred_samples,
            post_pred_samples=post_pred_samples,
            random_seed=random_seed,
            sample_kwargs=sample_kwargs,
        )
        self.mcmc_results = pmapi.convert_samples_to_arviz(self.model, _mcmc_results)
        logger.info(&#34;Finished MCMC sampling - caching results.&#34;)
        self.write_mcmc_cache()
        return self.mcmc_results

    def get_replacement_parameters(self) -&gt; Optional[ReplacementsDict]:
        &#34;&#34;&#34;Create a dictionary of PyMC3 variables to replace for ADVI fitting.

        This method is useful if you can take advantage of creating MiniBatch
        variables and replaced them using SharedVariables in the model. If not changed,
        this method returns None and has no effect on ADVI.

        Returns:
            Optional[ReplacementsDict]: Dictionary of variable replacements.
        &#34;&#34;&#34;
        return None

    def get_advi_callbacks(self) -&gt; List[Any]:
        &#34;&#34;&#34;Prepare a list of callbacks for ADVI fitting.

        This can be overridden by subclasses to apply custom callbacks or change the
        parameters of the CheckParametersConvergence callback.

        Returns:
            List[Any]: List of callbacks.
        &#34;&#34;&#34;
        return [
            pm.callbacks.CheckParametersConvergence(tolerance=0.01, diff=&#34;absolute&#34;)
        ]

    def update_advi_sampling_parameters(self) -&gt; None:
        &#34;&#34;&#34;Override if ADVI fitting parameters need to be adjusted.&#34;&#34;&#34;
        return None

    def advi_sample_model(
        self,
        method: Optional[str] = None,
        n_iterations: Optional[int] = None,
        draws: Optional[int] = None,
        prior_pred_samples: Optional[int] = None,
        post_pred_samples: Optional[int] = None,
        random_seed: Optional[int] = None,
        ignore_cache: bool = False,
    ) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;ADVI fit the model.

        This method primarily wraps the
          `pymc3_sampling_api.pymc3_advi_approximation_procedure()` function.

        Many of the key arguments default to None in the function call, but are replaced
        by the values in the `self.advi_sampling_params` attribute.

        Args:
            model (pm.Model): PyMC3 model.
            method (Optional[str], optional): VI method to use. Defaults to None.
            n_iterations (Optional[int]): Maximum number of fitting steps. Defaults to
              None.
            draws (Optional[int], optional): Number of MCMC samples to draw from the fit
              model. Defaults to None.
            prior_pred_samples (Optional[int], optional): Number of samples from the
              prior distributions. Defaults to None.
            post_pred_samples (Optional[int], optional): Number of samples for posterior
              predictions. Defaults to None.
            callbacks (List[Callable], optional): List of fitting callbacks. Default is
              None.
            random_seed (Optional[int], optional): The random seed for sampling.
              Defaults to None.
            fit_kwargs (Dict[str, Any], optional): Kwargs for the fitting method.
              Defaults to {}.

        Raises:
            AttributeError: Raised if the model does not yet exist.

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: The results of fitting the model
              and the approximation object.
        &#34;&#34;&#34;
        logger.debug(&#34;Beginning ADVI fitting method.&#34;)
        self.update_advi_sampling_parameters()
        if method is None:
            method = self.advi_sampling_params.method
        if n_iterations is None:
            n_iterations = self.advi_sampling_params.n_iterations
        if draws is None:
            draws = self.advi_sampling_params.draws
        if prior_pred_samples is None:
            prior_pred_samples = self.advi_sampling_params.prior_pred_samples
        if post_pred_samples is None:
            post_pred_samples = self.advi_sampling_params.post_pred_samples

        if self.model is None:
            raise AttributeError(
                &#34;Cannot sample: model is &#39;None&#39;. &#34;
                + &#34;Make sure to run `model.build_model()` first.&#34;
            )

        fit_kwargs: Dict[str, Any] = {}
        replacements = self.get_replacement_parameters()
        if replacements is not None:
            fit_kwargs[&#34;more_replacements&#34;] = replacements

        if self.advi_results is not None:
            logger.info(&#34;Returning results from stored `advi_results` attribute.&#34;)
            return self.advi_results

        if not ignore_cache and self.cache_manager.advi_cache_exists():
            logger.info(&#34;Returning results from cache.&#34;)
            self.advi_results = self.cache_manager.get_advi_cache()
            return self.advi_results

        logger.info(&#34;Beginning ADVI fitting.&#34;)
        _advi_results = pmapi.pymc3_advi_approximation_procedure(
            model=self.model,
            method=method,
            n_iterations=n_iterations,
            draws=draws,
            prior_pred_samples=prior_pred_samples,
            post_pred_samples=post_pred_samples,
            callbacks=self.get_advi_callbacks(),
            random_seed=random_seed,
            fit_kwargs=fit_kwargs,
        )
        self.advi_results = (
            pmapi.convert_samples_to_arviz(self.model, _advi_results),
            _advi_results.approximation,
        )
        logger.info(&#34;Finished ADVI fitting - caching results.&#34;)
        self.write_advi_cache()
        return self.advi_results

    def run_simulation_based_calibration(
        self,
        results_path: Path,
        fit_method: ModelFitMethod,
        size: MockDataSize,
        random_seed: Optional[int] = None,
        fit_kwargs: Optional[Dict[Any, Any]] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Run a round of simulation-based calibration.

        Args:
            results_path (Path): Where to store the results.
            fit_method (ModelFitMethod): Which method to use for fitting.
            random_seed (Optional[int], optional): Random seed (for reproducibility).
              Defaults to None.
            size (MockDataSize): Size of the data set to mock. Defaults to &#34;large&#34;.
            fit_kwargs (Optional[Dict[Any, Any]], optional): Keyword arguments to be
              passed to the fitting method. Default is None.
        &#34;&#34;&#34;
        if fit_kwargs is None:
            fit_kwargs = {}

        sbc_fm = sbc.SBCFileManager(dir=results_path)

        logger.info(&#34;Creating new simulation data.&#34;)
        mock_data = self.data_manager.generate_mock_data(
            size=size, random_seed=random_seed
        )

        logger.debug(&#34;Building model for SBC.&#34;)
        self.build_model()
        assert self.model is not None
        assert self.observed_var_name is not None

        logger.info(&#34;Sampling from the prior for mock values for SBC.&#34;)
        with self.model:
            priors = pm.sample_prior_predictive(samples=1, random_seed=random_seed)

        mock_data[self.observed_var_name] = priors.get(self.observed_var_name).flatten()
        self.data_manager.set_data(mock_data)
        sbc_fm.save_sbc_data(mock_data)

        # Update shared variable with adjusted observed data.
        logger.info(&#34;Updating observed value with prior-sampled values.&#34;)
        self.update_observed_data(mock_data[self.observed_var_name].values)

        logger.info(f&#34;Fitting model to mock data using {fit_method.value}.&#34;)
        if fit_method is ModelFitMethod.ADVI:
            res, _ = self.advi_sample_model(random_seed=random_seed, **fit_kwargs)
        elif fit_method is ModelFitMethod.MCMC:
            res = self.mcmc_sample_model(random_seed=random_seed, **fit_kwargs)
        else:
            assert_never(fit_method)

        logger.info(&#34;Making posterior summary for the SBC.&#34;)
        posterior_summary = az.summary(res, fmt=&#34;wide&#34;, hdi_prob=0.89)
        assert isinstance(posterior_summary, pd.DataFrame)

        logger.info(&#34;Using a SBC file manager to save SBC results.&#34;)
        sbc_fm.save_sbc_results(
            priors=priors,
            inference_obj=res,
            posterior_summary=posterior_summary,
        )

    def write_mcmc_cache(self) -&gt; None:
        &#34;&#34;&#34;Cache the MCMC sampling results.&#34;&#34;&#34;
        if self.mcmc_results is not None:
            self.cache_manager.write_mcmc_cache(self.mcmc_results)
        else:
            logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)

    def write_advi_cache(self) -&gt; None:
        &#34;&#34;&#34;Cache the ADVI sampling results.&#34;&#34;&#34;
        if self.advi_results is not None:
            self.cache_manager.write_advi_cache(
                self.advi_results[0], self.advi_results[1]
            )
        else:
            logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)

    def get_sbc(
        self, results_path: Path
    ) -&gt; tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]:
        &#34;&#34;&#34;Retrieve the data and results of an SBC.

        Args:
            results_path (Path): Directory containing the SBC results.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]: The simulated data,
            the SBC results, and the file manager for the SBC.
        &#34;&#34;&#34;
        sbc_fm = sbc.SBCFileManager(results_path)

        # Checks that data and results exist.
        if not sbc_fm.simulation_data_exists():
            raise CacheDoesNotExistError(sbc_fm.sbc_data_path)
        if not sbc_fm.all_data_exists():
            raise CacheDoesNotExistError(sbc_fm.dir)

        simulated_data = sbc_fm.get_sbc_data()
        sbc_results = sbc_fm.get_sbc_results()
        self.data_manager.set_data(simulated_data)
        if self.model is None:
            self.build_model()
        return self.data_manager.get_data(), sbc_results, sbc_fm

    def load_mcmc_cache(self) -&gt; az.InferenceData:
        &#34;&#34;&#34;Load MCMC from cache.

        Sets the cached MCMC result as the instance&#39;s `mcmc_results` attribute, too.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            az.InferenceData: Cached MCMC results.
        &#34;&#34;&#34;
        if self.cache_manager.mcmc_cache_exists():
            self.mcmc_results = self.cache_manager.get_mcmc_cache()
            return self.mcmc_results
        else:
            raise CacheDoesNotExistError(
                self.cache_manager.mcmc_cache_delegate.cache_dir
            )

    def load_advi_cache(self) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;Load ADVI from cache.

        Sets the cached ADVI result as the instance&#39;s `advi_results` attribute, too.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: Cached ADVI results.
        &#34;&#34;&#34;
        if self.cache_manager.advi_cache_exists():
            _advi_results = self.cache_manager.get_advi_cache()
            self.advi_results = _advi_results
            return _advi_results
        else:
            raise CacheDoesNotExistError(
                self.cache_manager.advi_cache_delegate.cache_dir
            )

    def update_observed_data(self, new_data: np.ndarray) -&gt; None:
        &#34;&#34;&#34;Update the values for the shared tensor for observed data.

        Args:
            new_data (np.ndarray): New data to set in the shared tensor.
        &#34;&#34;&#34;
        if self.shared_vars is None:
            raise SharedVariableDictionaryNotSet(
                &#34;Cannot locate shared variable dictionary.&#34;
            )
        _var_name = f&#34;{self.observed_var_name}_shared&#34;
        observed_var_shared = self.shared_vars.get(_var_name)
        if observed_var_shared is not None:
            observed_var_shared.set_value(new_data)
            logger.info(f&#34;Setting new data for observed variable: &#39;{_var_name}&#39;.&#34;)
        else:
            msg = f&#34;Unable to set new values for observed variable: &#39;{_var_name}&#39;.&#34;
            logger.error(msg)
            raise UnableToLocateNamedVariable(msg)

    def set_config(self, info: Dict[Any, Any]) -&gt; None:
        &#34;&#34;&#34;Set model-specific configuration.&#34;&#34;&#34;
        return None</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.models.speclet_model.MCMCSamplingParameters"><code class="flex name class">
<span>class <span class="ident">MCMCSamplingParameters</span></span>
<span>(</span><span>*, draws: int = 1000, prior_pred_samples: int = 1000, post_pred_samples: int = 1000, tune: int = 2000, cores: int = 4, chains: int = 4, init: str = 'auto', n_init: int = 200000, target_accept: float = 0.8)</span>
</code></dt>
<dd>
<div class="desc"><p>Parameters for MCMC sampling.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MCMCSamplingParameters(PyMC3SamplingParameters):
    &#34;&#34;&#34;Parameters for MCMC sampling.&#34;&#34;&#34;

    tune: int = 2000
    cores: int = 4
    chains: int = 4
    init: str = &#34;auto&#34;
    n_init: int = 200000
    target_accept: float = 0.8  # default for pm.NUTS</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.models.speclet_model.PyMC3SamplingParameters" href="#src.models.speclet_model.PyMC3SamplingParameters">PyMC3SamplingParameters</a></li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
</dd>
<dt id="src.models.speclet_model.PyMC3SamplingParameters"><code class="flex name class">
<span>class <span class="ident">PyMC3SamplingParameters</span></span>
<span>(</span><span>*, draws: int = 1000, prior_pred_samples: int = 1000, post_pred_samples: int = 1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Paramerers common to fitting a model in PyMC3.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PyMC3SamplingParameters(BaseModel):
    &#34;&#34;&#34;Paramerers common to fitting a model in PyMC3.&#34;&#34;&#34;

    draws: int = 1000
    prior_pred_samples: int = 1000
    post_pred_samples: int = 1000</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="src.models.speclet_model.MCMCSamplingParameters" href="#src.models.speclet_model.MCMCSamplingParameters">MCMCSamplingParameters</a></li>
<li><a title="src.models.speclet_model.VISamplingParameters" href="#src.models.speclet_model.VISamplingParameters">VISamplingParameters</a></li>
</ul>
</dd>
<dt id="src.models.speclet_model.SharedVariableDictionaryNotSet"><code class="flex name class">
<span>class <span class="ident">SharedVariableDictionaryNotSet</span></span>
<span>(</span><span>...)</span>
</code></dt>
<dd>
<div class="desc"><p>Error for when the shared variable dictionary should be available but is not.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SharedVariableDictionaryNotSet(AttributeError):
    &#34;&#34;&#34;Error for when the shared variable dictionary should be available but is not.&#34;&#34;&#34;

    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.AttributeError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="src.models.speclet_model.SpecletModel"><code class="flex name class">
<span>class <span class="ident">SpecletModel</span></span>
<span>(</span><span>name: str, data_manager: <a title="src.managers.model_data_managers.DataManager" href="../managers/model_data_managers.html#src.managers.model_data_managers.DataManager">DataManager</a>, root_cache_dir: Optional[pathlib.Path] = None, debug: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class to contain a PyMC3 model.</p>
<p>Instantiate a Speclet Model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the model.</dd>
<dt><strong><code>root_cache_dir</code></strong> :&ensp;<code>Optional[Path]</code>, optional</dt>
<dd>Location for the cache directory.
If None (default), then the project's default cache directory is used.
Defaults to None.</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Use debug mode? Defaults to False.</dd>
<dt><strong><code>data_manager</code></strong> :&ensp;<code>Optional[DataManager]</code>, optional</dt>
<dd>Object that will manage the
data. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpecletModel:
    &#34;&#34;&#34;Base class to contain a PyMC3 model.&#34;&#34;&#34;

    name: str
    _debug: bool
    cache_manager: Pymc3ModelCacheManager
    data_manager: DataManager

    model: Optional[pm.Model] = None
    observed_var_name: Optional[str] = None
    shared_vars: Optional[Dict[str, TTShared]] = None
    advi_results: Optional[Tuple[az.InferenceData, pm.Approximation]] = None
    mcmc_results: Optional[az.InferenceData] = None

    mcmc_sampling_params: MCMCSamplingParameters = MCMCSamplingParameters()
    advi_sampling_params: VISamplingParameters = VISamplingParameters()

    def __init__(
        self,
        name: str,
        data_manager: DataManager,
        root_cache_dir: Optional[Path] = None,
        debug: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;Instantiate a Speclet Model.

        Args:
            name (str): Name of the model.
            root_cache_dir (Optional[Path], optional): Location for the cache directory.
              If None (default), then the project&#39;s default cache directory is used.
              Defaults to None.
            debug (bool, optional): Use debug mode? Defaults to False.
            data_manager (Optional[DataManager], optional): Object that will manage the
              data. Defaults to None.
        &#34;&#34;&#34;
        self.name = name
        self._debug = debug
        self.cache_manager = Pymc3ModelCacheManager(
            name=name, root_cache_dir=root_cache_dir
        )
        self.data_manager = data_manager
        self.data_manager.debug = self._debug

    def __str__(self) -&gt; str:
        &#34;&#34;&#34;Describe the object.

        Returns:
            str: String description of the object.
        &#34;&#34;&#34;
        msg = f&#34;Speclet Model: &#39;{self.name}&#39;&#34;
        if self.debug:
            msg += &#34; (debug)&#34;
        return msg

    @property
    def debug(self) -&gt; bool:
        &#34;&#34;&#34;Whether or not to use debug mode.

        Returns:
            bool: The current value for debug mode.
        &#34;&#34;&#34;
        return self._debug

    @debug.setter
    def debug(self, new_value: bool) -&gt; None:
        &#34;&#34;&#34;Set the value for debug mode.

        This also changes the debug mode for the data manager. Changes are only made if
        the new value is different from the current value.

        Args:
            new_value (bool): New value for `debug`.
        &#34;&#34;&#34;
        if new_value == self._debug:
            return
        logger.info(f&#34;Changing value of debug to &#39;{new_value}&#39;.&#34;)
        self._debug = new_value
        if self.data_manager is not None:
            self.data_manager.debug = new_value

    def _reset_model_and_results(self, clear_cache: bool = False):
        logger.warning(&#34;Reseting all model and results.&#34;)
        self.model = None
        self.mcmc_results = None
        self.advi_results = None
        if clear_cache:
            self.clear_cache()

    def clear_cache(self):
        &#34;&#34;&#34;Clear all available caches for the model.&#34;&#34;&#34;
        self.cache_manager.clear_all_caches()

    @abstractmethod
    def model_specification(self) -&gt; Tuple[pm.Model, str]:
        &#34;&#34;&#34;Define the PyMC3 model.

        This model must be overridden by an subclass to define the desired PyMC3 model.

        Returns:
            pm.Model: The PyMC3 model.
            str: Name of the target variable in the model.
        &#34;&#34;&#34;
        raise Exception(
            &#34;The `model_specification()` method must be overridden by subclasses.&#34;
        )

    def build_model(self) -&gt; None:
        &#34;&#34;&#34;Build the PyMC3 model.

        Raises:
            AttributeError: Raised if there is no data manager.
            AttributeError: Raised the `model` attribute is still None after calling
              `self.model_specification()`
            AttributeError: Raised the `observed_var_name` attribute is still None
              after calling `self.model_specification()`
        &#34;&#34;&#34;
        logger.debug(&#34;Building PyMC3 model.&#34;)

        logger.info(&#34;Calling `model_specification()` method.&#34;)
        self.model, self.observed_var_name = self.model_specification()

        if self.model is None:
            m = &#34;The `model` attribute cannot be None at the end of the &#34;
            m += &#34;`build_model()` method.&#34;
            logger.error(m)
            raise AttributeError(m)

        if self.observed_var_name is None:
            m = &#34;The `observed_var_name` attribute cannot be None at the end of the &#34;
            m += &#34;`build_model()` method.&#34;
            logger.error(m)
            raise AttributeError(m)

        return None

    def update_mcmc_sampling_parameters(self) -&gt; None:
        &#34;&#34;&#34;Override if MCMC sampling parameters need to be adjusted.&#34;&#34;&#34;
        return None

    def mcmc_sample_model(
        self,
        draws: Optional[int] = None,
        tune: Optional[int] = None,
        chains: Optional[int] = None,
        cores: Optional[int] = None,
        target_accept: Optional[float] = None,
        prior_pred_samples: Optional[int] = None,
        post_pred_samples: Optional[int] = None,
        random_seed: Optional[int] = None,
        sample_kwargs: Optional[Dict[str, Any]] = None,
        ignore_cache: bool = False,
    ) -&gt; az.InferenceData:
        &#34;&#34;&#34;MCMC sample the model.

        This method primarily wraps the `pymc3_sampling_api.pymc3_sampling_procedure()`
        function.

        Many of the key arguments default to None in the function call, but are replaced
        by the values in the `self.mcmc_sampling_params` attribute.

        Args:
            mcmc_draws (Optional[int], optional): Number of MCMC draws. Defaults to
              None.
            tune (Optional[int], optional): Number of tuning steps. Defaults to None.
            chains (Optional[int], optional): Number of chains. Defaults to 3.
            cores (Optional[int], optional): Number of cores. Defaults to
              None.
            target_accept (Optional[float], optional): MCMC target acceptance. Defaults
              to None.
            prior_pred_samples (Optional[int], optional): Number of samples from the
              prior distributions. Defaults to None.
            post_pred_samples (Optional[int], optional): Number of samples for posterior
              predictions.
            Defaults to None.
            random_seed (Optional[int], optional): The random seed for sampling.
            Defaults to None.
            sample_kwargs (Dict[str, Any], optional): Kwargs for the sampling method.
            Defaults to {}.
            ignore_cache (bool, optional): Should any cached results be ignored?
              Defaults to False.

        Raises:
            AttributeError: Raised if the PyMC3 model does not yet exist.

        Returns:
            az.InferenceData: The results of MCMC sampling.
        &#34;&#34;&#34;
        logger.debug(&#34;Beginning MCMC sampling method.&#34;)
        self.update_mcmc_sampling_parameters()
        if draws is None:
            draws = self.mcmc_sampling_params.draws
        if tune is None:
            tune = self.mcmc_sampling_params.tune
        if chains is None:
            chains = self.mcmc_sampling_params.chains
        if cores is None:
            cores = self.mcmc_sampling_params.cores
        if target_accept is None:
            target_accept = self.mcmc_sampling_params.target_accept
        if prior_pred_samples is None:
            prior_pred_samples = self.mcmc_sampling_params.prior_pred_samples
        if post_pred_samples is None:
            post_pred_samples = self.mcmc_sampling_params.post_pred_samples

        if self.model is None:
            raise AttributeError(
                &#34;Cannot sample: model is &#39;None&#39;. &#34;
                + &#34;Make sure to run `model.build_model()` first.&#34;
            )

        if self.mcmc_results is not None:
            logger.info(&#34;Returning results from stored `mcmc_results` attribute.&#34;)
            return self.mcmc_results

        if not ignore_cache and self.cache_manager.mcmc_cache_exists():
            logger.info(&#34;Returning results from cache.&#34;)
            self.mcmc_results = self.cache_manager.get_mcmc_cache()
            return self.mcmc_results

        if sample_kwargs is None:
            sample_kwargs = {}
        sample_kwargs[&#34;target_accept&#34;] = target_accept

        logger.info(&#34;Beginning MCMC sampling.&#34;)
        _mcmc_results = pmapi.pymc3_sampling_procedure(
            model=self.model,
            mcmc_draws=draws,
            tune=tune,
            chains=chains,
            cores=cores,
            prior_pred_samples=prior_pred_samples,
            post_pred_samples=post_pred_samples,
            random_seed=random_seed,
            sample_kwargs=sample_kwargs,
        )
        self.mcmc_results = pmapi.convert_samples_to_arviz(self.model, _mcmc_results)
        logger.info(&#34;Finished MCMC sampling - caching results.&#34;)
        self.write_mcmc_cache()
        return self.mcmc_results

    def get_replacement_parameters(self) -&gt; Optional[ReplacementsDict]:
        &#34;&#34;&#34;Create a dictionary of PyMC3 variables to replace for ADVI fitting.

        This method is useful if you can take advantage of creating MiniBatch
        variables and replaced them using SharedVariables in the model. If not changed,
        this method returns None and has no effect on ADVI.

        Returns:
            Optional[ReplacementsDict]: Dictionary of variable replacements.
        &#34;&#34;&#34;
        return None

    def get_advi_callbacks(self) -&gt; List[Any]:
        &#34;&#34;&#34;Prepare a list of callbacks for ADVI fitting.

        This can be overridden by subclasses to apply custom callbacks or change the
        parameters of the CheckParametersConvergence callback.

        Returns:
            List[Any]: List of callbacks.
        &#34;&#34;&#34;
        return [
            pm.callbacks.CheckParametersConvergence(tolerance=0.01, diff=&#34;absolute&#34;)
        ]

    def update_advi_sampling_parameters(self) -&gt; None:
        &#34;&#34;&#34;Override if ADVI fitting parameters need to be adjusted.&#34;&#34;&#34;
        return None

    def advi_sample_model(
        self,
        method: Optional[str] = None,
        n_iterations: Optional[int] = None,
        draws: Optional[int] = None,
        prior_pred_samples: Optional[int] = None,
        post_pred_samples: Optional[int] = None,
        random_seed: Optional[int] = None,
        ignore_cache: bool = False,
    ) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;ADVI fit the model.

        This method primarily wraps the
          `pymc3_sampling_api.pymc3_advi_approximation_procedure()` function.

        Many of the key arguments default to None in the function call, but are replaced
        by the values in the `self.advi_sampling_params` attribute.

        Args:
            model (pm.Model): PyMC3 model.
            method (Optional[str], optional): VI method to use. Defaults to None.
            n_iterations (Optional[int]): Maximum number of fitting steps. Defaults to
              None.
            draws (Optional[int], optional): Number of MCMC samples to draw from the fit
              model. Defaults to None.
            prior_pred_samples (Optional[int], optional): Number of samples from the
              prior distributions. Defaults to None.
            post_pred_samples (Optional[int], optional): Number of samples for posterior
              predictions. Defaults to None.
            callbacks (List[Callable], optional): List of fitting callbacks. Default is
              None.
            random_seed (Optional[int], optional): The random seed for sampling.
              Defaults to None.
            fit_kwargs (Dict[str, Any], optional): Kwargs for the fitting method.
              Defaults to {}.

        Raises:
            AttributeError: Raised if the model does not yet exist.

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: The results of fitting the model
              and the approximation object.
        &#34;&#34;&#34;
        logger.debug(&#34;Beginning ADVI fitting method.&#34;)
        self.update_advi_sampling_parameters()
        if method is None:
            method = self.advi_sampling_params.method
        if n_iterations is None:
            n_iterations = self.advi_sampling_params.n_iterations
        if draws is None:
            draws = self.advi_sampling_params.draws
        if prior_pred_samples is None:
            prior_pred_samples = self.advi_sampling_params.prior_pred_samples
        if post_pred_samples is None:
            post_pred_samples = self.advi_sampling_params.post_pred_samples

        if self.model is None:
            raise AttributeError(
                &#34;Cannot sample: model is &#39;None&#39;. &#34;
                + &#34;Make sure to run `model.build_model()` first.&#34;
            )

        fit_kwargs: Dict[str, Any] = {}
        replacements = self.get_replacement_parameters()
        if replacements is not None:
            fit_kwargs[&#34;more_replacements&#34;] = replacements

        if self.advi_results is not None:
            logger.info(&#34;Returning results from stored `advi_results` attribute.&#34;)
            return self.advi_results

        if not ignore_cache and self.cache_manager.advi_cache_exists():
            logger.info(&#34;Returning results from cache.&#34;)
            self.advi_results = self.cache_manager.get_advi_cache()
            return self.advi_results

        logger.info(&#34;Beginning ADVI fitting.&#34;)
        _advi_results = pmapi.pymc3_advi_approximation_procedure(
            model=self.model,
            method=method,
            n_iterations=n_iterations,
            draws=draws,
            prior_pred_samples=prior_pred_samples,
            post_pred_samples=post_pred_samples,
            callbacks=self.get_advi_callbacks(),
            random_seed=random_seed,
            fit_kwargs=fit_kwargs,
        )
        self.advi_results = (
            pmapi.convert_samples_to_arviz(self.model, _advi_results),
            _advi_results.approximation,
        )
        logger.info(&#34;Finished ADVI fitting - caching results.&#34;)
        self.write_advi_cache()
        return self.advi_results

    def run_simulation_based_calibration(
        self,
        results_path: Path,
        fit_method: ModelFitMethod,
        size: MockDataSize,
        random_seed: Optional[int] = None,
        fit_kwargs: Optional[Dict[Any, Any]] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Run a round of simulation-based calibration.

        Args:
            results_path (Path): Where to store the results.
            fit_method (ModelFitMethod): Which method to use for fitting.
            random_seed (Optional[int], optional): Random seed (for reproducibility).
              Defaults to None.
            size (MockDataSize): Size of the data set to mock. Defaults to &#34;large&#34;.
            fit_kwargs (Optional[Dict[Any, Any]], optional): Keyword arguments to be
              passed to the fitting method. Default is None.
        &#34;&#34;&#34;
        if fit_kwargs is None:
            fit_kwargs = {}

        sbc_fm = sbc.SBCFileManager(dir=results_path)

        logger.info(&#34;Creating new simulation data.&#34;)
        mock_data = self.data_manager.generate_mock_data(
            size=size, random_seed=random_seed
        )

        logger.debug(&#34;Building model for SBC.&#34;)
        self.build_model()
        assert self.model is not None
        assert self.observed_var_name is not None

        logger.info(&#34;Sampling from the prior for mock values for SBC.&#34;)
        with self.model:
            priors = pm.sample_prior_predictive(samples=1, random_seed=random_seed)

        mock_data[self.observed_var_name] = priors.get(self.observed_var_name).flatten()
        self.data_manager.set_data(mock_data)
        sbc_fm.save_sbc_data(mock_data)

        # Update shared variable with adjusted observed data.
        logger.info(&#34;Updating observed value with prior-sampled values.&#34;)
        self.update_observed_data(mock_data[self.observed_var_name].values)

        logger.info(f&#34;Fitting model to mock data using {fit_method.value}.&#34;)
        if fit_method is ModelFitMethod.ADVI:
            res, _ = self.advi_sample_model(random_seed=random_seed, **fit_kwargs)
        elif fit_method is ModelFitMethod.MCMC:
            res = self.mcmc_sample_model(random_seed=random_seed, **fit_kwargs)
        else:
            assert_never(fit_method)

        logger.info(&#34;Making posterior summary for the SBC.&#34;)
        posterior_summary = az.summary(res, fmt=&#34;wide&#34;, hdi_prob=0.89)
        assert isinstance(posterior_summary, pd.DataFrame)

        logger.info(&#34;Using a SBC file manager to save SBC results.&#34;)
        sbc_fm.save_sbc_results(
            priors=priors,
            inference_obj=res,
            posterior_summary=posterior_summary,
        )

    def write_mcmc_cache(self) -&gt; None:
        &#34;&#34;&#34;Cache the MCMC sampling results.&#34;&#34;&#34;
        if self.mcmc_results is not None:
            self.cache_manager.write_mcmc_cache(self.mcmc_results)
        else:
            logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)

    def write_advi_cache(self) -&gt; None:
        &#34;&#34;&#34;Cache the ADVI sampling results.&#34;&#34;&#34;
        if self.advi_results is not None:
            self.cache_manager.write_advi_cache(
                self.advi_results[0], self.advi_results[1]
            )
        else:
            logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)

    def get_sbc(
        self, results_path: Path
    ) -&gt; tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]:
        &#34;&#34;&#34;Retrieve the data and results of an SBC.

        Args:
            results_path (Path): Directory containing the SBC results.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]: The simulated data,
            the SBC results, and the file manager for the SBC.
        &#34;&#34;&#34;
        sbc_fm = sbc.SBCFileManager(results_path)

        # Checks that data and results exist.
        if not sbc_fm.simulation_data_exists():
            raise CacheDoesNotExistError(sbc_fm.sbc_data_path)
        if not sbc_fm.all_data_exists():
            raise CacheDoesNotExistError(sbc_fm.dir)

        simulated_data = sbc_fm.get_sbc_data()
        sbc_results = sbc_fm.get_sbc_results()
        self.data_manager.set_data(simulated_data)
        if self.model is None:
            self.build_model()
        return self.data_manager.get_data(), sbc_results, sbc_fm

    def load_mcmc_cache(self) -&gt; az.InferenceData:
        &#34;&#34;&#34;Load MCMC from cache.

        Sets the cached MCMC result as the instance&#39;s `mcmc_results` attribute, too.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            az.InferenceData: Cached MCMC results.
        &#34;&#34;&#34;
        if self.cache_manager.mcmc_cache_exists():
            self.mcmc_results = self.cache_manager.get_mcmc_cache()
            return self.mcmc_results
        else:
            raise CacheDoesNotExistError(
                self.cache_manager.mcmc_cache_delegate.cache_dir
            )

    def load_advi_cache(self) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;Load ADVI from cache.

        Sets the cached ADVI result as the instance&#39;s `advi_results` attribute, too.

        Raises:
            CacheDoesNotExistError: Raised if the cache does not exist.

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: Cached ADVI results.
        &#34;&#34;&#34;
        if self.cache_manager.advi_cache_exists():
            _advi_results = self.cache_manager.get_advi_cache()
            self.advi_results = _advi_results
            return _advi_results
        else:
            raise CacheDoesNotExistError(
                self.cache_manager.advi_cache_delegate.cache_dir
            )

    def update_observed_data(self, new_data: np.ndarray) -&gt; None:
        &#34;&#34;&#34;Update the values for the shared tensor for observed data.

        Args:
            new_data (np.ndarray): New data to set in the shared tensor.
        &#34;&#34;&#34;
        if self.shared_vars is None:
            raise SharedVariableDictionaryNotSet(
                &#34;Cannot locate shared variable dictionary.&#34;
            )
        _var_name = f&#34;{self.observed_var_name}_shared&#34;
        observed_var_shared = self.shared_vars.get(_var_name)
        if observed_var_shared is not None:
            observed_var_shared.set_value(new_data)
            logger.info(f&#34;Setting new data for observed variable: &#39;{_var_name}&#39;.&#34;)
        else:
            msg = f&#34;Unable to set new values for observed variable: &#39;{_var_name}&#39;.&#34;
            logger.error(msg)
            raise UnableToLocateNamedVariable(msg)

    def set_config(self, info: Dict[Any, Any]) -&gt; None:
        &#34;&#34;&#34;Set model-specific configuration.&#34;&#34;&#34;
        return None</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="src.models.ceres_mimic.CeresMimic" href="ceres_mimic.html#src.models.ceres_mimic.CeresMimic">CeresMimic</a></li>
<li><a title="src.models.speclet_five.SpecletFive" href="speclet_five.html#src.models.speclet_five.SpecletFive">SpecletFive</a></li>
<li><a title="src.models.speclet_four.SpecletFour" href="speclet_four.html#src.models.speclet_four.SpecletFour">SpecletFour</a></li>
<li><a title="src.models.speclet_one.SpecletOne" href="speclet_one.html#src.models.speclet_one.SpecletOne">SpecletOne</a></li>
<li><a title="src.models.speclet_pipeline_test_model.SpecletTestModel" href="speclet_pipeline_test_model.html#src.models.speclet_pipeline_test_model.SpecletTestModel">SpecletTestModel</a></li>
<li><a title="src.models.speclet_seven.SpecletSeven" href="speclet_seven.html#src.models.speclet_seven.SpecletSeven">SpecletSeven</a></li>
<li><a title="src.models.speclet_six.SpecletSix" href="speclet_six.html#src.models.speclet_six.SpecletSix">SpecletSix</a></li>
<li><a title="src.models.speclet_two.SpecletTwo" href="speclet_two.html#src.models.speclet_two.SpecletTwo">SpecletTwo</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.models.speclet_model.SpecletModel.advi_results"><code class="name">var <span class="ident">advi_results</span> : Optional[Tuple[arviz.data.inference_data.InferenceData, pymc3.variational.opvi.Approximation]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.advi_sampling_params"><code class="name">var <span class="ident">advi_sampling_params</span> : <a title="src.models.speclet_model.VISamplingParameters" href="#src.models.speclet_model.VISamplingParameters">VISamplingParameters</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.mcmc_results"><code class="name">var <span class="ident">mcmc_results</span> : Optional[arviz.data.inference_data.InferenceData]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.mcmc_sampling_params"><code class="name">var <span class="ident">mcmc_sampling_params</span> : <a title="src.models.speclet_model.MCMCSamplingParameters" href="#src.models.speclet_model.MCMCSamplingParameters">MCMCSamplingParameters</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.model"><code class="name">var <span class="ident">model</span> : Optional[pymc3.model.Model]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.observed_var_name"><code class="name">var <span class="ident">observed_var_name</span> : Optional[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.models.speclet_model.SpecletModel.shared_vars"><code class="name">var <span class="ident">shared_vars</span> : Optional[Dict[str, theano.tensor.sharedvar.TensorSharedVariable]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="src.models.speclet_model.SpecletModel.debug"><code class="name">var <span class="ident">debug</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether or not to use debug mode.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>The current value for debug mode.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def debug(self) -&gt; bool:
    &#34;&#34;&#34;Whether or not to use debug mode.

    Returns:
        bool: The current value for debug mode.
    &#34;&#34;&#34;
    return self._debug</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.models.speclet_model.SpecletModel.advi_sample_model"><code class="name flex">
<span>def <span class="ident">advi_sample_model</span></span>(<span>self, method: Optional[str] = None, n_iterations: Optional[int] = None, draws: Optional[int] = None, prior_pred_samples: Optional[int] = None, post_pred_samples: Optional[int] = None, random_seed: Optional[int] = None, ignore_cache: bool = False) -> Tuple[arviz.data.inference_data.InferenceData, pymc3.variational.opvi.Approximation]</span>
</code></dt>
<dd>
<div class="desc"><p>ADVI fit the model.</p>
<p>This method primarily wraps the
<code>pymc3_sampling_api.pymc3_advi_approximation_procedure()</code> function.</p>
<p>Many of the key arguments default to None in the function call, but are replaced
by the values in the <code>self.advi_sampling_params</code> attribute.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>pm.Model</code></dt>
<dd>PyMC3 model.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>VI method to use. Defaults to None.</dd>
<dt><strong><code>n_iterations</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>Maximum number of fitting steps. Defaults to
None.</dd>
<dt><strong><code>draws</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of MCMC samples to draw from the fit
model. Defaults to None.</dd>
<dt><strong><code>prior_pred_samples</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of samples from the
prior distributions. Defaults to None.</dd>
<dt><strong><code>post_pred_samples</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of samples for posterior
predictions. Defaults to None.</dd>
<dt><strong><code>callbacks</code></strong> :&ensp;<code>List[Callable]</code>, optional</dt>
<dd>List of fitting callbacks. Default is
None.</dd>
<dt><strong><code>random_seed</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>The random seed for sampling.
Defaults to None.</dd>
<dt><strong><code>fit_kwargs</code></strong> :&ensp;<code>Dict[str, Any]</code>, optional</dt>
<dd>Kwargs for the fitting method.
Defaults to {}.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>AttributeError</code></dt>
<dd>Raised if the model does not yet exist.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[az.InferenceData, pm.Approximation]</code></dt>
<dd>The results of fitting the model
and the approximation object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def advi_sample_model(
    self,
    method: Optional[str] = None,
    n_iterations: Optional[int] = None,
    draws: Optional[int] = None,
    prior_pred_samples: Optional[int] = None,
    post_pred_samples: Optional[int] = None,
    random_seed: Optional[int] = None,
    ignore_cache: bool = False,
) -&gt; Tuple[az.InferenceData, pm.Approximation]:
    &#34;&#34;&#34;ADVI fit the model.

    This method primarily wraps the
      `pymc3_sampling_api.pymc3_advi_approximation_procedure()` function.

    Many of the key arguments default to None in the function call, but are replaced
    by the values in the `self.advi_sampling_params` attribute.

    Args:
        model (pm.Model): PyMC3 model.
        method (Optional[str], optional): VI method to use. Defaults to None.
        n_iterations (Optional[int]): Maximum number of fitting steps. Defaults to
          None.
        draws (Optional[int], optional): Number of MCMC samples to draw from the fit
          model. Defaults to None.
        prior_pred_samples (Optional[int], optional): Number of samples from the
          prior distributions. Defaults to None.
        post_pred_samples (Optional[int], optional): Number of samples for posterior
          predictions. Defaults to None.
        callbacks (List[Callable], optional): List of fitting callbacks. Default is
          None.
        random_seed (Optional[int], optional): The random seed for sampling.
          Defaults to None.
        fit_kwargs (Dict[str, Any], optional): Kwargs for the fitting method.
          Defaults to {}.

    Raises:
        AttributeError: Raised if the model does not yet exist.

    Returns:
        Tuple[az.InferenceData, pm.Approximation]: The results of fitting the model
          and the approximation object.
    &#34;&#34;&#34;
    logger.debug(&#34;Beginning ADVI fitting method.&#34;)
    self.update_advi_sampling_parameters()
    if method is None:
        method = self.advi_sampling_params.method
    if n_iterations is None:
        n_iterations = self.advi_sampling_params.n_iterations
    if draws is None:
        draws = self.advi_sampling_params.draws
    if prior_pred_samples is None:
        prior_pred_samples = self.advi_sampling_params.prior_pred_samples
    if post_pred_samples is None:
        post_pred_samples = self.advi_sampling_params.post_pred_samples

    if self.model is None:
        raise AttributeError(
            &#34;Cannot sample: model is &#39;None&#39;. &#34;
            + &#34;Make sure to run `model.build_model()` first.&#34;
        )

    fit_kwargs: Dict[str, Any] = {}
    replacements = self.get_replacement_parameters()
    if replacements is not None:
        fit_kwargs[&#34;more_replacements&#34;] = replacements

    if self.advi_results is not None:
        logger.info(&#34;Returning results from stored `advi_results` attribute.&#34;)
        return self.advi_results

    if not ignore_cache and self.cache_manager.advi_cache_exists():
        logger.info(&#34;Returning results from cache.&#34;)
        self.advi_results = self.cache_manager.get_advi_cache()
        return self.advi_results

    logger.info(&#34;Beginning ADVI fitting.&#34;)
    _advi_results = pmapi.pymc3_advi_approximation_procedure(
        model=self.model,
        method=method,
        n_iterations=n_iterations,
        draws=draws,
        prior_pred_samples=prior_pred_samples,
        post_pred_samples=post_pred_samples,
        callbacks=self.get_advi_callbacks(),
        random_seed=random_seed,
        fit_kwargs=fit_kwargs,
    )
    self.advi_results = (
        pmapi.convert_samples_to_arviz(self.model, _advi_results),
        _advi_results.approximation,
    )
    logger.info(&#34;Finished ADVI fitting - caching results.&#34;)
    self.write_advi_cache()
    return self.advi_results</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.build_model"><code class="name flex">
<span>def <span class="ident">build_model</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Build the PyMC3 model.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>AttributeError</code></dt>
<dd>Raised if there is no data manager.</dd>
<dt><code>AttributeError</code></dt>
<dd>Raised the <code>model</code> attribute is still None after calling
<code>self.model_specification()</code></dd>
<dt><code>AttributeError</code></dt>
<dd>Raised the <code>observed_var_name</code> attribute is still None
after calling <code>self.model_specification()</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_model(self) -&gt; None:
    &#34;&#34;&#34;Build the PyMC3 model.

    Raises:
        AttributeError: Raised if there is no data manager.
        AttributeError: Raised the `model` attribute is still None after calling
          `self.model_specification()`
        AttributeError: Raised the `observed_var_name` attribute is still None
          after calling `self.model_specification()`
    &#34;&#34;&#34;
    logger.debug(&#34;Building PyMC3 model.&#34;)

    logger.info(&#34;Calling `model_specification()` method.&#34;)
    self.model, self.observed_var_name = self.model_specification()

    if self.model is None:
        m = &#34;The `model` attribute cannot be None at the end of the &#34;
        m += &#34;`build_model()` method.&#34;
        logger.error(m)
        raise AttributeError(m)

    if self.observed_var_name is None:
        m = &#34;The `observed_var_name` attribute cannot be None at the end of the &#34;
        m += &#34;`build_model()` method.&#34;
        logger.error(m)
        raise AttributeError(m)

    return None</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.clear_cache"><code class="name flex">
<span>def <span class="ident">clear_cache</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Clear all available caches for the model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_cache(self):
    &#34;&#34;&#34;Clear all available caches for the model.&#34;&#34;&#34;
    self.cache_manager.clear_all_caches()</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.get_advi_callbacks"><code class="name flex">
<span>def <span class="ident">get_advi_callbacks</span></span>(<span>self) -> List[Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare a list of callbacks for ADVI fitting.</p>
<p>This can be overridden by subclasses to apply custom callbacks or change the
parameters of the CheckParametersConvergence callback.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Any]</code></dt>
<dd>List of callbacks.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_advi_callbacks(self) -&gt; List[Any]:
    &#34;&#34;&#34;Prepare a list of callbacks for ADVI fitting.

    This can be overridden by subclasses to apply custom callbacks or change the
    parameters of the CheckParametersConvergence callback.

    Returns:
        List[Any]: List of callbacks.
    &#34;&#34;&#34;
    return [
        pm.callbacks.CheckParametersConvergence(tolerance=0.01, diff=&#34;absolute&#34;)
    ]</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.get_replacement_parameters"><code class="name flex">
<span>def <span class="ident">get_replacement_parameters</span></span>(<span>self) -> Optional[Dict[theano.tensor.sharedvar.TensorSharedVariable, Union[pymc3.data.Minibatch, numpy.ndarray]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Create a dictionary of PyMC3 variables to replace for ADVI fitting.</p>
<p>This method is useful if you can take advantage of creating MiniBatch
variables and replaced them using SharedVariables in the model. If not changed,
this method returns None and has no effect on ADVI.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Optional[ReplacementsDict]</code></dt>
<dd>Dictionary of variable replacements.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_replacement_parameters(self) -&gt; Optional[ReplacementsDict]:
    &#34;&#34;&#34;Create a dictionary of PyMC3 variables to replace for ADVI fitting.

    This method is useful if you can take advantage of creating MiniBatch
    variables and replaced them using SharedVariables in the model. If not changed,
    this method returns None and has no effect on ADVI.

    Returns:
        Optional[ReplacementsDict]: Dictionary of variable replacements.
    &#34;&#34;&#34;
    return None</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.get_sbc"><code class="name flex">
<span>def <span class="ident">get_sbc</span></span>(<span>self, results_path: pathlib.Path) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the data and results of an SBC.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>results_path</code></strong> :&ensp;<code>Path</code></dt>
<dd>Directory containing the SBC results.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>CacheDoesNotExistError</code></dt>
<dd>Raised if the cache does not exist.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]</code></dt>
<dd>The simulated data,</dd>
</dl>
<p>the SBC results, and the file manager for the SBC.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sbc(
    self, results_path: Path
) -&gt; tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]:
    &#34;&#34;&#34;Retrieve the data and results of an SBC.

    Args:
        results_path (Path): Directory containing the SBC results.

    Raises:
        CacheDoesNotExistError: Raised if the cache does not exist.

    Returns:
        tuple[pd.DataFrame, sbc.SBCResults, sbc.SBCFileManager]: The simulated data,
        the SBC results, and the file manager for the SBC.
    &#34;&#34;&#34;
    sbc_fm = sbc.SBCFileManager(results_path)

    # Checks that data and results exist.
    if not sbc_fm.simulation_data_exists():
        raise CacheDoesNotExistError(sbc_fm.sbc_data_path)
    if not sbc_fm.all_data_exists():
        raise CacheDoesNotExistError(sbc_fm.dir)

    simulated_data = sbc_fm.get_sbc_data()
    sbc_results = sbc_fm.get_sbc_results()
    self.data_manager.set_data(simulated_data)
    if self.model is None:
        self.build_model()
    return self.data_manager.get_data(), sbc_results, sbc_fm</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.load_advi_cache"><code class="name flex">
<span>def <span class="ident">load_advi_cache</span></span>(<span>self) -> Tuple[arviz.data.inference_data.InferenceData, pymc3.variational.opvi.Approximation]</span>
</code></dt>
<dd>
<div class="desc"><p>Load ADVI from cache.</p>
<p>Sets the cached ADVI result as the instance's <code>advi_results</code> attribute, too.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>CacheDoesNotExistError</code></dt>
<dd>Raised if the cache does not exist.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[az.InferenceData, pm.Approximation]</code></dt>
<dd>Cached ADVI results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_advi_cache(self) -&gt; Tuple[az.InferenceData, pm.Approximation]:
    &#34;&#34;&#34;Load ADVI from cache.

    Sets the cached ADVI result as the instance&#39;s `advi_results` attribute, too.

    Raises:
        CacheDoesNotExistError: Raised if the cache does not exist.

    Returns:
        Tuple[az.InferenceData, pm.Approximation]: Cached ADVI results.
    &#34;&#34;&#34;
    if self.cache_manager.advi_cache_exists():
        _advi_results = self.cache_manager.get_advi_cache()
        self.advi_results = _advi_results
        return _advi_results
    else:
        raise CacheDoesNotExistError(
            self.cache_manager.advi_cache_delegate.cache_dir
        )</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.load_mcmc_cache"><code class="name flex">
<span>def <span class="ident">load_mcmc_cache</span></span>(<span>self) -> arviz.data.inference_data.InferenceData</span>
</code></dt>
<dd>
<div class="desc"><p>Load MCMC from cache.</p>
<p>Sets the cached MCMC result as the instance's <code>mcmc_results</code> attribute, too.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>CacheDoesNotExistError</code></dt>
<dd>Raised if the cache does not exist.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>az.InferenceData</code></dt>
<dd>Cached MCMC results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_mcmc_cache(self) -&gt; az.InferenceData:
    &#34;&#34;&#34;Load MCMC from cache.

    Sets the cached MCMC result as the instance&#39;s `mcmc_results` attribute, too.

    Raises:
        CacheDoesNotExistError: Raised if the cache does not exist.

    Returns:
        az.InferenceData: Cached MCMC results.
    &#34;&#34;&#34;
    if self.cache_manager.mcmc_cache_exists():
        self.mcmc_results = self.cache_manager.get_mcmc_cache()
        return self.mcmc_results
    else:
        raise CacheDoesNotExistError(
            self.cache_manager.mcmc_cache_delegate.cache_dir
        )</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.mcmc_sample_model"><code class="name flex">
<span>def <span class="ident">mcmc_sample_model</span></span>(<span>self, draws: Optional[int] = None, tune: Optional[int] = None, chains: Optional[int] = None, cores: Optional[int] = None, target_accept: Optional[float] = None, prior_pred_samples: Optional[int] = None, post_pred_samples: Optional[int] = None, random_seed: Optional[int] = None, sample_kwargs: Optional[Dict[str, Any]] = None, ignore_cache: bool = False) -> arviz.data.inference_data.InferenceData</span>
</code></dt>
<dd>
<div class="desc"><p>MCMC sample the model.</p>
<p>This method primarily wraps the <code>pymc3_sampling_api.pymc3_sampling_procedure()</code>
function.</p>
<p>Many of the key arguments default to None in the function call, but are replaced
by the values in the <code>self.mcmc_sampling_params</code> attribute.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mcmc_draws</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of MCMC draws. Defaults to
None.</dd>
<dt><strong><code>tune</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of tuning steps. Defaults to None.</dd>
<dt><strong><code>chains</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of chains. Defaults to 3.</dd>
<dt><strong><code>cores</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of cores. Defaults to
None.</dd>
<dt><strong><code>target_accept</code></strong> :&ensp;<code>Optional[float]</code>, optional</dt>
<dd>MCMC target acceptance. Defaults
to None.</dd>
<dt><strong><code>prior_pred_samples</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of samples from the
prior distributions. Defaults to None.</dd>
<dt><strong><code>post_pred_samples</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Number of samples for posterior
predictions.</dd>
<dt>Defaults to None.</dt>
<dt><strong><code>random_seed</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>The random seed for sampling.</dd>
<dt>Defaults to None.</dt>
<dt><strong><code>sample_kwargs</code></strong> :&ensp;<code>Dict[str, Any]</code>, optional</dt>
<dd>Kwargs for the sampling method.</dd>
<dt>Defaults to {}.</dt>
<dt><strong><code>ignore_cache</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Should any cached results be ignored?
Defaults to False.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>AttributeError</code></dt>
<dd>Raised if the PyMC3 model does not yet exist.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>az.InferenceData</code></dt>
<dd>The results of MCMC sampling.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mcmc_sample_model(
    self,
    draws: Optional[int] = None,
    tune: Optional[int] = None,
    chains: Optional[int] = None,
    cores: Optional[int] = None,
    target_accept: Optional[float] = None,
    prior_pred_samples: Optional[int] = None,
    post_pred_samples: Optional[int] = None,
    random_seed: Optional[int] = None,
    sample_kwargs: Optional[Dict[str, Any]] = None,
    ignore_cache: bool = False,
) -&gt; az.InferenceData:
    &#34;&#34;&#34;MCMC sample the model.

    This method primarily wraps the `pymc3_sampling_api.pymc3_sampling_procedure()`
    function.

    Many of the key arguments default to None in the function call, but are replaced
    by the values in the `self.mcmc_sampling_params` attribute.

    Args:
        mcmc_draws (Optional[int], optional): Number of MCMC draws. Defaults to
          None.
        tune (Optional[int], optional): Number of tuning steps. Defaults to None.
        chains (Optional[int], optional): Number of chains. Defaults to 3.
        cores (Optional[int], optional): Number of cores. Defaults to
          None.
        target_accept (Optional[float], optional): MCMC target acceptance. Defaults
          to None.
        prior_pred_samples (Optional[int], optional): Number of samples from the
          prior distributions. Defaults to None.
        post_pred_samples (Optional[int], optional): Number of samples for posterior
          predictions.
        Defaults to None.
        random_seed (Optional[int], optional): The random seed for sampling.
        Defaults to None.
        sample_kwargs (Dict[str, Any], optional): Kwargs for the sampling method.
        Defaults to {}.
        ignore_cache (bool, optional): Should any cached results be ignored?
          Defaults to False.

    Raises:
        AttributeError: Raised if the PyMC3 model does not yet exist.

    Returns:
        az.InferenceData: The results of MCMC sampling.
    &#34;&#34;&#34;
    logger.debug(&#34;Beginning MCMC sampling method.&#34;)
    self.update_mcmc_sampling_parameters()
    if draws is None:
        draws = self.mcmc_sampling_params.draws
    if tune is None:
        tune = self.mcmc_sampling_params.tune
    if chains is None:
        chains = self.mcmc_sampling_params.chains
    if cores is None:
        cores = self.mcmc_sampling_params.cores
    if target_accept is None:
        target_accept = self.mcmc_sampling_params.target_accept
    if prior_pred_samples is None:
        prior_pred_samples = self.mcmc_sampling_params.prior_pred_samples
    if post_pred_samples is None:
        post_pred_samples = self.mcmc_sampling_params.post_pred_samples

    if self.model is None:
        raise AttributeError(
            &#34;Cannot sample: model is &#39;None&#39;. &#34;
            + &#34;Make sure to run `model.build_model()` first.&#34;
        )

    if self.mcmc_results is not None:
        logger.info(&#34;Returning results from stored `mcmc_results` attribute.&#34;)
        return self.mcmc_results

    if not ignore_cache and self.cache_manager.mcmc_cache_exists():
        logger.info(&#34;Returning results from cache.&#34;)
        self.mcmc_results = self.cache_manager.get_mcmc_cache()
        return self.mcmc_results

    if sample_kwargs is None:
        sample_kwargs = {}
    sample_kwargs[&#34;target_accept&#34;] = target_accept

    logger.info(&#34;Beginning MCMC sampling.&#34;)
    _mcmc_results = pmapi.pymc3_sampling_procedure(
        model=self.model,
        mcmc_draws=draws,
        tune=tune,
        chains=chains,
        cores=cores,
        prior_pred_samples=prior_pred_samples,
        post_pred_samples=post_pred_samples,
        random_seed=random_seed,
        sample_kwargs=sample_kwargs,
    )
    self.mcmc_results = pmapi.convert_samples_to_arviz(self.model, _mcmc_results)
    logger.info(&#34;Finished MCMC sampling - caching results.&#34;)
    self.write_mcmc_cache()
    return self.mcmc_results</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.model_specification"><code class="name flex">
<span>def <span class="ident">model_specification</span></span>(<span>self) -> Tuple[pymc3.model.Model, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the PyMC3 model.</p>
<p>This model must be overridden by an subclass to define the desired PyMC3 model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pm.Model</code></dt>
<dd>The PyMC3 model.</dd>
<dt><code>str</code></dt>
<dd>Name of the target variable in the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def model_specification(self) -&gt; Tuple[pm.Model, str]:
    &#34;&#34;&#34;Define the PyMC3 model.

    This model must be overridden by an subclass to define the desired PyMC3 model.

    Returns:
        pm.Model: The PyMC3 model.
        str: Name of the target variable in the model.
    &#34;&#34;&#34;
    raise Exception(
        &#34;The `model_specification()` method must be overridden by subclasses.&#34;
    )</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.run_simulation_based_calibration"><code class="name flex">
<span>def <span class="ident">run_simulation_based_calibration</span></span>(<span>self, results_path: pathlib.Path, fit_method: <a title="src.project_enums.ModelFitMethod" href="../project_enums.html#src.project_enums.ModelFitMethod">ModelFitMethod</a>, size: <a title="src.project_enums.MockDataSize" href="../project_enums.html#src.project_enums.MockDataSize">MockDataSize</a>, random_seed: Optional[int] = None, fit_kwargs: Optional[Dict[Any, Any]] = None) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Run a round of simulation-based calibration.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>results_path</code></strong> :&ensp;<code>Path</code></dt>
<dd>Where to store the results.</dd>
<dt><strong><code>fit_method</code></strong> :&ensp;<code>ModelFitMethod</code></dt>
<dd>Which method to use for fitting.</dd>
<dt><strong><code>random_seed</code></strong> :&ensp;<code>Optional[int]</code>, optional</dt>
<dd>Random seed (for reproducibility).
Defaults to None.</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>MockDataSize</code></dt>
<dd>Size of the data set to mock. Defaults to "large".</dd>
<dt><strong><code>fit_kwargs</code></strong> :&ensp;<code>Optional[Dict[Any, Any]]</code>, optional</dt>
<dd>Keyword arguments to be
passed to the fitting method. Default is None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_simulation_based_calibration(
    self,
    results_path: Path,
    fit_method: ModelFitMethod,
    size: MockDataSize,
    random_seed: Optional[int] = None,
    fit_kwargs: Optional[Dict[Any, Any]] = None,
) -&gt; None:
    &#34;&#34;&#34;Run a round of simulation-based calibration.

    Args:
        results_path (Path): Where to store the results.
        fit_method (ModelFitMethod): Which method to use for fitting.
        random_seed (Optional[int], optional): Random seed (for reproducibility).
          Defaults to None.
        size (MockDataSize): Size of the data set to mock. Defaults to &#34;large&#34;.
        fit_kwargs (Optional[Dict[Any, Any]], optional): Keyword arguments to be
          passed to the fitting method. Default is None.
    &#34;&#34;&#34;
    if fit_kwargs is None:
        fit_kwargs = {}

    sbc_fm = sbc.SBCFileManager(dir=results_path)

    logger.info(&#34;Creating new simulation data.&#34;)
    mock_data = self.data_manager.generate_mock_data(
        size=size, random_seed=random_seed
    )

    logger.debug(&#34;Building model for SBC.&#34;)
    self.build_model()
    assert self.model is not None
    assert self.observed_var_name is not None

    logger.info(&#34;Sampling from the prior for mock values for SBC.&#34;)
    with self.model:
        priors = pm.sample_prior_predictive(samples=1, random_seed=random_seed)

    mock_data[self.observed_var_name] = priors.get(self.observed_var_name).flatten()
    self.data_manager.set_data(mock_data)
    sbc_fm.save_sbc_data(mock_data)

    # Update shared variable with adjusted observed data.
    logger.info(&#34;Updating observed value with prior-sampled values.&#34;)
    self.update_observed_data(mock_data[self.observed_var_name].values)

    logger.info(f&#34;Fitting model to mock data using {fit_method.value}.&#34;)
    if fit_method is ModelFitMethod.ADVI:
        res, _ = self.advi_sample_model(random_seed=random_seed, **fit_kwargs)
    elif fit_method is ModelFitMethod.MCMC:
        res = self.mcmc_sample_model(random_seed=random_seed, **fit_kwargs)
    else:
        assert_never(fit_method)

    logger.info(&#34;Making posterior summary for the SBC.&#34;)
    posterior_summary = az.summary(res, fmt=&#34;wide&#34;, hdi_prob=0.89)
    assert isinstance(posterior_summary, pd.DataFrame)

    logger.info(&#34;Using a SBC file manager to save SBC results.&#34;)
    sbc_fm.save_sbc_results(
        priors=priors,
        inference_obj=res,
        posterior_summary=posterior_summary,
    )</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.set_config"><code class="name flex">
<span>def <span class="ident">set_config</span></span>(<span>self, info: Dict[Any, Any]) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Set model-specific configuration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_config(self, info: Dict[Any, Any]) -&gt; None:
    &#34;&#34;&#34;Set model-specific configuration.&#34;&#34;&#34;
    return None</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.update_advi_sampling_parameters"><code class="name flex">
<span>def <span class="ident">update_advi_sampling_parameters</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Override if ADVI fitting parameters need to be adjusted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_advi_sampling_parameters(self) -&gt; None:
    &#34;&#34;&#34;Override if ADVI fitting parameters need to be adjusted.&#34;&#34;&#34;
    return None</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.update_mcmc_sampling_parameters"><code class="name flex">
<span>def <span class="ident">update_mcmc_sampling_parameters</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Override if MCMC sampling parameters need to be adjusted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_mcmc_sampling_parameters(self) -&gt; None:
    &#34;&#34;&#34;Override if MCMC sampling parameters need to be adjusted.&#34;&#34;&#34;
    return None</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.update_observed_data"><code class="name flex">
<span>def <span class="ident">update_observed_data</span></span>(<span>self, new_data: numpy.ndarray) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Update the values for the shared tensor for observed data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>new_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>New data to set in the shared tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_observed_data(self, new_data: np.ndarray) -&gt; None:
    &#34;&#34;&#34;Update the values for the shared tensor for observed data.

    Args:
        new_data (np.ndarray): New data to set in the shared tensor.
    &#34;&#34;&#34;
    if self.shared_vars is None:
        raise SharedVariableDictionaryNotSet(
            &#34;Cannot locate shared variable dictionary.&#34;
        )
    _var_name = f&#34;{self.observed_var_name}_shared&#34;
    observed_var_shared = self.shared_vars.get(_var_name)
    if observed_var_shared is not None:
        observed_var_shared.set_value(new_data)
        logger.info(f&#34;Setting new data for observed variable: &#39;{_var_name}&#39;.&#34;)
    else:
        msg = f&#34;Unable to set new values for observed variable: &#39;{_var_name}&#39;.&#34;
        logger.error(msg)
        raise UnableToLocateNamedVariable(msg)</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.write_advi_cache"><code class="name flex">
<span>def <span class="ident">write_advi_cache</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Cache the ADVI sampling results.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_advi_cache(self) -&gt; None:
    &#34;&#34;&#34;Cache the ADVI sampling results.&#34;&#34;&#34;
    if self.advi_results is not None:
        self.cache_manager.write_advi_cache(
            self.advi_results[0], self.advi_results[1]
        )
    else:
        logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)</code></pre>
</details>
</dd>
<dt id="src.models.speclet_model.SpecletModel.write_mcmc_cache"><code class="name flex">
<span>def <span class="ident">write_mcmc_cache</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Cache the MCMC sampling results.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_mcmc_cache(self) -&gt; None:
    &#34;&#34;&#34;Cache the MCMC sampling results.&#34;&#34;&#34;
    if self.mcmc_results is not None:
        self.cache_manager.write_mcmc_cache(self.mcmc_results)
    else:
        logger.warning(&#34;Did not cache MCMC samples because they do not exist.&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.models.speclet_model.UnableToLocateNamedVariable"><code class="flex name class">
<span>class <span class="ident">UnableToLocateNamedVariable</span></span>
<span>(</span><span>...)</span>
</code></dt>
<dd>
<div class="desc"><p>Error when a named variable or object cannot be located.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UnableToLocateNamedVariable(Exception):
    &#34;&#34;&#34;Error when a named variable or object cannot be located.&#34;&#34;&#34;

    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="src.models.speclet_model.VISamplingParameters"><code class="flex name class">
<span>class <span class="ident">VISamplingParameters</span></span>
<span>(</span><span>*, draws: int = 1000, prior_pred_samples: int = 1000, post_pred_samples: int = 1000, method: str = 'advi', n_iterations: int = 50000)</span>
</code></dt>
<dd>
<div class="desc"><p>Parameters for fitting by VI.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VISamplingParameters(PyMC3SamplingParameters):
    &#34;&#34;&#34;Parameters for fitting by VI.&#34;&#34;&#34;

    method: str = &#34;advi&#34;
    n_iterations: int = 50000</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.models.speclet_model.PyMC3SamplingParameters" href="#src.models.speclet_model.PyMC3SamplingParameters">PyMC3SamplingParameters</a></li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.models" href="index.html">src.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.models.speclet_model.MCMCSamplingParameters" href="#src.models.speclet_model.MCMCSamplingParameters">MCMCSamplingParameters</a></code></h4>
</li>
<li>
<h4><code><a title="src.models.speclet_model.PyMC3SamplingParameters" href="#src.models.speclet_model.PyMC3SamplingParameters">PyMC3SamplingParameters</a></code></h4>
</li>
<li>
<h4><code><a title="src.models.speclet_model.SharedVariableDictionaryNotSet" href="#src.models.speclet_model.SharedVariableDictionaryNotSet">SharedVariableDictionaryNotSet</a></code></h4>
</li>
<li>
<h4><code><a title="src.models.speclet_model.SpecletModel" href="#src.models.speclet_model.SpecletModel">SpecletModel</a></code></h4>
<ul class="">
<li><code><a title="src.models.speclet_model.SpecletModel.advi_results" href="#src.models.speclet_model.SpecletModel.advi_results">advi_results</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.advi_sample_model" href="#src.models.speclet_model.SpecletModel.advi_sample_model">advi_sample_model</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.advi_sampling_params" href="#src.models.speclet_model.SpecletModel.advi_sampling_params">advi_sampling_params</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.build_model" href="#src.models.speclet_model.SpecletModel.build_model">build_model</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.clear_cache" href="#src.models.speclet_model.SpecletModel.clear_cache">clear_cache</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.debug" href="#src.models.speclet_model.SpecletModel.debug">debug</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.get_advi_callbacks" href="#src.models.speclet_model.SpecletModel.get_advi_callbacks">get_advi_callbacks</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.get_replacement_parameters" href="#src.models.speclet_model.SpecletModel.get_replacement_parameters">get_replacement_parameters</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.get_sbc" href="#src.models.speclet_model.SpecletModel.get_sbc">get_sbc</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.load_advi_cache" href="#src.models.speclet_model.SpecletModel.load_advi_cache">load_advi_cache</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.load_mcmc_cache" href="#src.models.speclet_model.SpecletModel.load_mcmc_cache">load_mcmc_cache</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.mcmc_results" href="#src.models.speclet_model.SpecletModel.mcmc_results">mcmc_results</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.mcmc_sample_model" href="#src.models.speclet_model.SpecletModel.mcmc_sample_model">mcmc_sample_model</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.mcmc_sampling_params" href="#src.models.speclet_model.SpecletModel.mcmc_sampling_params">mcmc_sampling_params</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.model" href="#src.models.speclet_model.SpecletModel.model">model</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.model_specification" href="#src.models.speclet_model.SpecletModel.model_specification">model_specification</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.observed_var_name" href="#src.models.speclet_model.SpecletModel.observed_var_name">observed_var_name</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.run_simulation_based_calibration" href="#src.models.speclet_model.SpecletModel.run_simulation_based_calibration">run_simulation_based_calibration</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.set_config" href="#src.models.speclet_model.SpecletModel.set_config">set_config</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.shared_vars" href="#src.models.speclet_model.SpecletModel.shared_vars">shared_vars</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.update_advi_sampling_parameters" href="#src.models.speclet_model.SpecletModel.update_advi_sampling_parameters">update_advi_sampling_parameters</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.update_mcmc_sampling_parameters" href="#src.models.speclet_model.SpecletModel.update_mcmc_sampling_parameters">update_mcmc_sampling_parameters</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.update_observed_data" href="#src.models.speclet_model.SpecletModel.update_observed_data">update_observed_data</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.write_advi_cache" href="#src.models.speclet_model.SpecletModel.write_advi_cache">write_advi_cache</a></code></li>
<li><code><a title="src.models.speclet_model.SpecletModel.write_mcmc_cache" href="#src.models.speclet_model.SpecletModel.write_mcmc_cache">write_mcmc_cache</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.models.speclet_model.UnableToLocateNamedVariable" href="#src.models.speclet_model.UnableToLocateNamedVariable">UnableToLocateNamedVariable</a></code></h4>
</li>
<li>
<h4><code><a title="src.models.speclet_model.VISamplingParameters" href="#src.models.speclet_model.VISamplingParameters">VISamplingParameters</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>