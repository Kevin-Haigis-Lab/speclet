<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>src.managers.cache_managers API documentation</title>
<meta name="description" content="PyMC3 model cache manager." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.managers.cache_managers</code></h1>
</header>
<section id="section-intro">
<p>PyMC3 model cache manager.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3

&#34;&#34;&#34;PyMC3 model cache manager.&#34;&#34;&#34;

import pickle
import shutil
from pathlib import Path
from typing import Any, Optional, Tuple, Union

import arviz as az
import pymc3 as pm
from pydantic import BaseModel

from src.loggers import logger
from src.modeling import pymc3_sampling_api as pmapi


class ModelComponentCachePaths(BaseModel):
    &#34;&#34;&#34;Paths for caching model components.&#34;&#34;&#34;

    trace_path: Path
    prior_predictive_path: Path
    posterior_predictive_path: Path
    approximation_path: Path


class ArvizCachePaths(BaseModel):
    &#34;&#34;&#34;Paths for caching ArviZ data.&#34;&#34;&#34;

    inference_data_path: Path
    approximation_path: Path


def _mkdir(dir: Path):
    if not dir.exists():
        dir.mkdir(parents=True)


def _write_pickle(x: Any, fp: Path) -&gt; None:
    with open(fp, &#34;wb&#34;) as f:
        pickle.dump(x, f)
    return None


def _get_pickle(fp: Path) -&gt; Any:
    with open(fp, &#34;rb&#34;) as f:
        d = pickle.load(f)
    return d


class Pymc3CacheManager:
    &#34;&#34;&#34;PyMC3 model cache manager.&#34;&#34;&#34;

    cache_dir: Path

    def __init__(self, cache_dir: Path):
        &#34;&#34;&#34;Instantiate a new Pymc3CacheManager object.

        Args:
            cache_dir (Path): The directory for caching sampling/fitting results.
        &#34;&#34;&#34;
        self.cache_dir = cache_dir
        _mkdir(self.cache_dir)

    def get_cache_file_names(self) -&gt; ModelComponentCachePaths:
        &#34;&#34;&#34;Generate standard caching file paths.

        Raises:
            ValueError: Thrown if `self.cache_dir` is None.

        Returns:
            ModelComponentCachePaths: Object containing the paths to use for caching
              various results from fitting a model.
        &#34;&#34;&#34;
        if self.cache_dir is None:
            raise ValueError(
                &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
            )
        trace_dir_path = self.cache_dir / &#34;pm-trace&#34;
        prior_file_path = self.cache_dir / &#34;prior-predictive-check.pkl&#34;
        post_file_path = self.cache_dir / &#34;posterior-predictive-check.pkl&#34;
        approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
        return ModelComponentCachePaths(
            trace_path=trace_dir_path,
            prior_predictive_path=prior_file_path,
            posterior_predictive_path=post_file_path,
            approximation_path=approx_file_path,
        )

    def read_cached_sampling(self, model: pm.Model) -&gt; pmapi.MCMCSamplingResults:
        &#34;&#34;&#34;Read sampling from cache.

        Args:
            model (pm.Model): The model corresponding to the cached sampling.

        Returns:
            pmapi.MCMCSamplingResults: The cached data.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()

        trace = pm.load_trace(cache_paths.trace_path.as_posix(), model=model)
        post_check = _get_pickle(cache_paths.posterior_predictive_path)
        prior_check = _get_pickle(cache_paths.prior_predictive_path)

        return pmapi.MCMCSamplingResults(
            trace=trace, prior_predictive=prior_check, posterior_predictive=post_check
        )

    def read_cached_approximation(
        self, draws: int = 1000
    ) -&gt; pmapi.ApproximationSamplingResults:
        &#34;&#34;&#34;Read VI Approximation results from cache.

        Args:
            draws (int, optional): The number of draws from the trace. Default is 1000.

        Returns:
            pmapi.ApproximationSamplingResults: The cached data.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()

        post_check = _get_pickle(cache_paths.posterior_predictive_path)
        prior_check = _get_pickle(cache_paths.prior_predictive_path)
        approx = _get_pickle(cache_paths.approximation_path)
        trace = approx.sample(draws)

        return pmapi.ApproximationSamplingResults(
            trace=trace,
            prior_predictive=prior_check,
            posterior_predictive=post_check,
            approximation=approx,
        )

    def cache_sampling_results(
        self, res: Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]
    ) -&gt; None:
        &#34;&#34;&#34;Cache sampling results to disk.

        Args:
            res (Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]):
              The results to cache.
        &#34;&#34;&#34;
        _mkdir(self.cache_dir)
        cache_paths = self.get_cache_file_names()
        _write_pickle(res.posterior_predictive, cache_paths.posterior_predictive_path)
        _write_pickle(res.prior_predictive, cache_paths.prior_predictive_path)
        if isinstance(res, pmapi.ApproximationSamplingResults):
            _write_pickle(res.approximation, cache_paths.approximation_path)
        elif isinstance(res, pmapi.MCMCSamplingResults):
            pm.save_trace(
                res.trace, directory=cache_paths.trace_path.as_posix(), overwrite=True
            )

    def cache_exists(self, method: str) -&gt; bool:
        &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

        This method checks for each pickle file and the trace directory (if applicable).

        Args:
            method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

        Returns:
            bool: Does the cache exist?

        Raises:
            ValueError: If the passed method is not an acceptable option.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()
        if (
            not cache_paths.prior_predictive_path.exists()
            or not cache_paths.posterior_predictive_path
        ):
            return False

        if method == &#34;mcmc&#34;:
            return cache_paths.trace_path.exists()
        elif method == &#34;approx&#34;:
            return cache_paths.approximation_path.exists()
        else:
            raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)

    def clear_cache(self) -&gt; bool:
        &#34;&#34;&#34;Remove the cache directory.

        Returns:
            bool: Whether the directory was removed or not. Returns False if the
              directory did not exist.
        &#34;&#34;&#34;
        if self.cache_dir.exists():
            shutil.rmtree(self.cache_dir)
            return True
        return False


class ArvizCacheManager:
    &#34;&#34;&#34;Cache of model results using ArviZ&#39;s InferenceData object.&#34;&#34;&#34;

    cache_dir: Path

    def __init__(self, cache_dir: Path):
        &#34;&#34;&#34;Instantiate a new ArvizCacheManager object.

        Args:
            cache_dir (Path): The directory for caching sampling/fitting results.
        &#34;&#34;&#34;
        self.cache_dir = cache_dir
        _mkdir(self.cache_dir)

    def get_cache_file_names(self) -&gt; ArvizCachePaths:
        &#34;&#34;&#34;Generate standard caching file paths.

        Raises:
            ValueError: Thrown if `self.cache_dir` is None.

        Returns:
            ArvizCachePaths: Object containing the paths to use for caching the ArviZ
              InferenceObject and approximation object.
        &#34;&#34;&#34;
        if self.cache_dir is None:
            raise ValueError(
                &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
            )
        inference_data_file_path = self.cache_dir / &#34;inference-data.nc&#34;
        approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
        return ArvizCachePaths(
            inference_data_path=inference_data_file_path,
            approximation_path=approx_file_path,
        )

    def cache_sampling_results(
        self,
        inference_data: az.InferenceData,
        approximation: Optional[pm.Approximation] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Cache sampling results to disk.

        Args:
            inference_data (az.InferenceData): ArviZ InferenceData with sampling
              results.
            approximation (Optional[pm.Approximation], optional): Approximation results
              for VI methods. Defaults to None.
        &#34;&#34;&#34;
        _mkdir(self.cache_dir)
        cache_paths = self.get_cache_file_names()
        logger.info(
            f&#34;Caching InferenceData to &#39;{cache_paths.inference_data_path.as_posix()}&#39;.&#34;
        )
        inference_data.to_netcdf(filename=cache_paths.inference_data_path.as_posix())
        if approximation is not None:
            logger.info(
                f&#34;Caching approx. to &#39;{cache_paths.approximation_path.as_posix()}&#39;.&#34;
            )
            _write_pickle(approximation, cache_paths.approximation_path)

    def cache_exists(self, method: str) -&gt; bool:
        &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

        Args:
            method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

        Raises:
            ValueError: If the passed method is not an acceptable option.

        Returns:
            bool: Does the cache exist?
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()
        if not cache_paths.inference_data_path.exists():
            return False

        if method == &#34;mcmc&#34;:
            # Nothing implemented at the moment.
            logger.info(&#34;ArvizCacheManager: MCMC cache exists.&#34;)
            return True
        elif method == &#34;approx&#34;:
            if cache_paths.approximation_path.exists():
                logger.info(&#34;ArvizCacheManager: ADVI cache exists.&#34;)
                return True
            return False
        else:
            raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)

    def read_cached_sampling(self, check_exists: bool = True) -&gt; az.InferenceData:
        &#34;&#34;&#34;Read sampling from cache.

        Args:
            check_exists (bool, optional): Should the existence of the cache be checked
              first? Defaults to True.

        Raises:
            FileNotFoundError: If the cache does not exists (only if
            `check_exists = True`).

        Returns:
            az.InferenceData: The cached data.
        &#34;&#34;&#34;
        logger.debug(&#34;Reading sampling cache from file.&#34;)
        cache_paths = self.get_cache_file_names()
        if check_exists:
            if not self.cache_exists(method=&#34;mcmc&#34;):
                raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
        return az.from_netcdf(cache_paths.inference_data_path.as_posix())

    def read_cached_approximation(
        self, check_exists: bool = True
    ) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;Read VI Approximation results from cache.

        Args:
            check_exists (bool, optional): Should the existence of the cache be checked
              first? Defaults to True.

        Raises:
            FileNotFoundError: If the cache does not exists (only if
            `check_exists = True`).

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: The cached data.
        &#34;&#34;&#34;
        logger.debug(&#34;Reading approximation cache from file.&#34;)
        cache_paths = self.get_cache_file_names()
        if check_exists:
            if not self.cache_exists(method=&#34;approx&#34;):
                raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
        inf_data = self.read_cached_sampling(check_exists=False)
        approx = _get_pickle(cache_paths.approximation_path)
        return inf_data, approx

    def clear_cache(self) -&gt; bool:
        &#34;&#34;&#34;Remove the cache directory.

        Returns:
            bool: Whether the directory was removed or not. Returns False if the
              directory did not exist.
        &#34;&#34;&#34;
        logger.debug(&#34;Trying to clear cache.&#34;)
        if self.cache_dir.exists():
            shutil.rmtree(self.cache_dir)
            return True
        return False</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.managers.cache_managers.ArvizCacheManager"><code class="flex name class">
<span>class <span class="ident">ArvizCacheManager</span></span>
<span>(</span><span>cache_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Cache of model results using ArviZ's InferenceData object.</p>
<p>Instantiate a new ArvizCacheManager object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cache_dir</code></strong> :&ensp;<code>Path</code></dt>
<dd>The directory for caching sampling/fitting results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ArvizCacheManager:
    &#34;&#34;&#34;Cache of model results using ArviZ&#39;s InferenceData object.&#34;&#34;&#34;

    cache_dir: Path

    def __init__(self, cache_dir: Path):
        &#34;&#34;&#34;Instantiate a new ArvizCacheManager object.

        Args:
            cache_dir (Path): The directory for caching sampling/fitting results.
        &#34;&#34;&#34;
        self.cache_dir = cache_dir
        _mkdir(self.cache_dir)

    def get_cache_file_names(self) -&gt; ArvizCachePaths:
        &#34;&#34;&#34;Generate standard caching file paths.

        Raises:
            ValueError: Thrown if `self.cache_dir` is None.

        Returns:
            ArvizCachePaths: Object containing the paths to use for caching the ArviZ
              InferenceObject and approximation object.
        &#34;&#34;&#34;
        if self.cache_dir is None:
            raise ValueError(
                &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
            )
        inference_data_file_path = self.cache_dir / &#34;inference-data.nc&#34;
        approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
        return ArvizCachePaths(
            inference_data_path=inference_data_file_path,
            approximation_path=approx_file_path,
        )

    def cache_sampling_results(
        self,
        inference_data: az.InferenceData,
        approximation: Optional[pm.Approximation] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Cache sampling results to disk.

        Args:
            inference_data (az.InferenceData): ArviZ InferenceData with sampling
              results.
            approximation (Optional[pm.Approximation], optional): Approximation results
              for VI methods. Defaults to None.
        &#34;&#34;&#34;
        _mkdir(self.cache_dir)
        cache_paths = self.get_cache_file_names()
        logger.info(
            f&#34;Caching InferenceData to &#39;{cache_paths.inference_data_path.as_posix()}&#39;.&#34;
        )
        inference_data.to_netcdf(filename=cache_paths.inference_data_path.as_posix())
        if approximation is not None:
            logger.info(
                f&#34;Caching approx. to &#39;{cache_paths.approximation_path.as_posix()}&#39;.&#34;
            )
            _write_pickle(approximation, cache_paths.approximation_path)

    def cache_exists(self, method: str) -&gt; bool:
        &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

        Args:
            method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

        Raises:
            ValueError: If the passed method is not an acceptable option.

        Returns:
            bool: Does the cache exist?
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()
        if not cache_paths.inference_data_path.exists():
            return False

        if method == &#34;mcmc&#34;:
            # Nothing implemented at the moment.
            logger.info(&#34;ArvizCacheManager: MCMC cache exists.&#34;)
            return True
        elif method == &#34;approx&#34;:
            if cache_paths.approximation_path.exists():
                logger.info(&#34;ArvizCacheManager: ADVI cache exists.&#34;)
                return True
            return False
        else:
            raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)

    def read_cached_sampling(self, check_exists: bool = True) -&gt; az.InferenceData:
        &#34;&#34;&#34;Read sampling from cache.

        Args:
            check_exists (bool, optional): Should the existence of the cache be checked
              first? Defaults to True.

        Raises:
            FileNotFoundError: If the cache does not exists (only if
            `check_exists = True`).

        Returns:
            az.InferenceData: The cached data.
        &#34;&#34;&#34;
        logger.debug(&#34;Reading sampling cache from file.&#34;)
        cache_paths = self.get_cache_file_names()
        if check_exists:
            if not self.cache_exists(method=&#34;mcmc&#34;):
                raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
        return az.from_netcdf(cache_paths.inference_data_path.as_posix())

    def read_cached_approximation(
        self, check_exists: bool = True
    ) -&gt; Tuple[az.InferenceData, pm.Approximation]:
        &#34;&#34;&#34;Read VI Approximation results from cache.

        Args:
            check_exists (bool, optional): Should the existence of the cache be checked
              first? Defaults to True.

        Raises:
            FileNotFoundError: If the cache does not exists (only if
            `check_exists = True`).

        Returns:
            Tuple[az.InferenceData, pm.Approximation]: The cached data.
        &#34;&#34;&#34;
        logger.debug(&#34;Reading approximation cache from file.&#34;)
        cache_paths = self.get_cache_file_names()
        if check_exists:
            if not self.cache_exists(method=&#34;approx&#34;):
                raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
        inf_data = self.read_cached_sampling(check_exists=False)
        approx = _get_pickle(cache_paths.approximation_path)
        return inf_data, approx

    def clear_cache(self) -&gt; bool:
        &#34;&#34;&#34;Remove the cache directory.

        Returns:
            bool: Whether the directory was removed or not. Returns False if the
              directory did not exist.
        &#34;&#34;&#34;
        logger.debug(&#34;Trying to clear cache.&#34;)
        if self.cache_dir.exists():
            shutil.rmtree(self.cache_dir)
            return True
        return False</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.managers.cache_managers.ArvizCacheManager.cache_exists"><code class="name flex">
<span>def <span class="ident">cache_exists</span></span>(<span>self, method: str) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Confirm that the cached sampling/fitting results exist.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Which cache to look for (either "mcmc" or "approx").</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the passed method is not an acceptable option.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Does the cache exist?</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cache_exists(self, method: str) -&gt; bool:
    &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

    Args:
        method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

    Raises:
        ValueError: If the passed method is not an acceptable option.

    Returns:
        bool: Does the cache exist?
    &#34;&#34;&#34;
    cache_paths = self.get_cache_file_names()
    if not cache_paths.inference_data_path.exists():
        return False

    if method == &#34;mcmc&#34;:
        # Nothing implemented at the moment.
        logger.info(&#34;ArvizCacheManager: MCMC cache exists.&#34;)
        return True
    elif method == &#34;approx&#34;:
        if cache_paths.approximation_path.exists():
            logger.info(&#34;ArvizCacheManager: ADVI cache exists.&#34;)
            return True
        return False
    else:
        raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.ArvizCacheManager.cache_sampling_results"><code class="name flex">
<span>def <span class="ident">cache_sampling_results</span></span>(<span>self, inference_data: arviz.data.inference_data.InferenceData, approximation: Optional[pymc3.variational.opvi.Approximation] = None) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Cache sampling results to disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inference_data</code></strong> :&ensp;<code>az.InferenceData</code></dt>
<dd>ArviZ InferenceData with sampling
results.</dd>
<dt><strong><code>approximation</code></strong> :&ensp;<code>Optional[pm.Approximation]</code>, optional</dt>
<dd>Approximation results
for VI methods. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cache_sampling_results(
    self,
    inference_data: az.InferenceData,
    approximation: Optional[pm.Approximation] = None,
) -&gt; None:
    &#34;&#34;&#34;Cache sampling results to disk.

    Args:
        inference_data (az.InferenceData): ArviZ InferenceData with sampling
          results.
        approximation (Optional[pm.Approximation], optional): Approximation results
          for VI methods. Defaults to None.
    &#34;&#34;&#34;
    _mkdir(self.cache_dir)
    cache_paths = self.get_cache_file_names()
    logger.info(
        f&#34;Caching InferenceData to &#39;{cache_paths.inference_data_path.as_posix()}&#39;.&#34;
    )
    inference_data.to_netcdf(filename=cache_paths.inference_data_path.as_posix())
    if approximation is not None:
        logger.info(
            f&#34;Caching approx. to &#39;{cache_paths.approximation_path.as_posix()}&#39;.&#34;
        )
        _write_pickle(approximation, cache_paths.approximation_path)</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.ArvizCacheManager.clear_cache"><code class="name flex">
<span>def <span class="ident">clear_cache</span></span>(<span>self) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the cache directory.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether the directory was removed or not. Returns False if the
directory did not exist.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_cache(self) -&gt; bool:
    &#34;&#34;&#34;Remove the cache directory.

    Returns:
        bool: Whether the directory was removed or not. Returns False if the
          directory did not exist.
    &#34;&#34;&#34;
    logger.debug(&#34;Trying to clear cache.&#34;)
    if self.cache_dir.exists():
        shutil.rmtree(self.cache_dir)
        return True
    return False</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.ArvizCacheManager.get_cache_file_names"><code class="name flex">
<span>def <span class="ident">get_cache_file_names</span></span>(<span>self) -> <a title="src.managers.cache_managers.ArvizCachePaths" href="#src.managers.cache_managers.ArvizCachePaths">ArvizCachePaths</a></span>
</code></dt>
<dd>
<div class="desc"><p>Generate standard caching file paths.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>Thrown if <code>self.cache_dir</code> is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="src.managers.cache_managers.ArvizCachePaths" href="#src.managers.cache_managers.ArvizCachePaths">ArvizCachePaths</a></code></dt>
<dd>Object containing the paths to use for caching the ArviZ
InferenceObject and approximation object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cache_file_names(self) -&gt; ArvizCachePaths:
    &#34;&#34;&#34;Generate standard caching file paths.

    Raises:
        ValueError: Thrown if `self.cache_dir` is None.

    Returns:
        ArvizCachePaths: Object containing the paths to use for caching the ArviZ
          InferenceObject and approximation object.
    &#34;&#34;&#34;
    if self.cache_dir is None:
        raise ValueError(
            &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
        )
    inference_data_file_path = self.cache_dir / &#34;inference-data.nc&#34;
    approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
    return ArvizCachePaths(
        inference_data_path=inference_data_file_path,
        approximation_path=approx_file_path,
    )</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.ArvizCacheManager.read_cached_approximation"><code class="name flex">
<span>def <span class="ident">read_cached_approximation</span></span>(<span>self, check_exists: bool = True) -> Tuple[arviz.data.inference_data.InferenceData, pymc3.variational.opvi.Approximation]</span>
</code></dt>
<dd>
<div class="desc"><p>Read VI Approximation results from cache.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>check_exists</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Should the existence of the cache be checked
first? Defaults to True.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>FileNotFoundError</code></dt>
<dd>If the cache does not exists (only if</dd>
</dl>
<p><code>check_exists = True</code>).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[az.InferenceData, pm.Approximation]</code></dt>
<dd>The cached data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_cached_approximation(
    self, check_exists: bool = True
) -&gt; Tuple[az.InferenceData, pm.Approximation]:
    &#34;&#34;&#34;Read VI Approximation results from cache.

    Args:
        check_exists (bool, optional): Should the existence of the cache be checked
          first? Defaults to True.

    Raises:
        FileNotFoundError: If the cache does not exists (only if
        `check_exists = True`).

    Returns:
        Tuple[az.InferenceData, pm.Approximation]: The cached data.
    &#34;&#34;&#34;
    logger.debug(&#34;Reading approximation cache from file.&#34;)
    cache_paths = self.get_cache_file_names()
    if check_exists:
        if not self.cache_exists(method=&#34;approx&#34;):
            raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
    inf_data = self.read_cached_sampling(check_exists=False)
    approx = _get_pickle(cache_paths.approximation_path)
    return inf_data, approx</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.ArvizCacheManager.read_cached_sampling"><code class="name flex">
<span>def <span class="ident">read_cached_sampling</span></span>(<span>self, check_exists: bool = True) -> arviz.data.inference_data.InferenceData</span>
</code></dt>
<dd>
<div class="desc"><p>Read sampling from cache.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>check_exists</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Should the existence of the cache be checked
first? Defaults to True.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>FileNotFoundError</code></dt>
<dd>If the cache does not exists (only if</dd>
</dl>
<p><code>check_exists = True</code>).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>az.InferenceData</code></dt>
<dd>The cached data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_cached_sampling(self, check_exists: bool = True) -&gt; az.InferenceData:
    &#34;&#34;&#34;Read sampling from cache.

    Args:
        check_exists (bool, optional): Should the existence of the cache be checked
          first? Defaults to True.

    Raises:
        FileNotFoundError: If the cache does not exists (only if
        `check_exists = True`).

    Returns:
        az.InferenceData: The cached data.
    &#34;&#34;&#34;
    logger.debug(&#34;Reading sampling cache from file.&#34;)
    cache_paths = self.get_cache_file_names()
    if check_exists:
        if not self.cache_exists(method=&#34;mcmc&#34;):
            raise FileNotFoundError(&#34;Cannot locate cached data.&#34;)
    return az.from_netcdf(cache_paths.inference_data_path.as_posix())</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.managers.cache_managers.ArvizCachePaths"><code class="flex name class">
<span>class <span class="ident">ArvizCachePaths</span></span>
<span>(</span><span>*, inference_data_path: pathlib.Path, approximation_path: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Paths for caching ArviZ data.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ArvizCachePaths(BaseModel):
    &#34;&#34;&#34;Paths for caching ArviZ data.&#34;&#34;&#34;

    inference_data_path: Path
    approximation_path: Path</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
</dd>
<dt id="src.managers.cache_managers.ModelComponentCachePaths"><code class="flex name class">
<span>class <span class="ident">ModelComponentCachePaths</span></span>
<span>(</span><span>*, trace_path: pathlib.Path, prior_predictive_path: pathlib.Path, posterior_predictive_path: pathlib.Path, approximation_path: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Paths for caching model components.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelComponentCachePaths(BaseModel):
    &#34;&#34;&#34;Paths for caching model components.&#34;&#34;&#34;

    trace_path: Path
    prior_predictive_path: Path
    posterior_predictive_path: Path
    approximation_path: Path</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager"><code class="flex name class">
<span>class <span class="ident">Pymc3CacheManager</span></span>
<span>(</span><span>cache_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>PyMC3 model cache manager.</p>
<p>Instantiate a new Pymc3CacheManager object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cache_dir</code></strong> :&ensp;<code>Path</code></dt>
<dd>The directory for caching sampling/fitting results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Pymc3CacheManager:
    &#34;&#34;&#34;PyMC3 model cache manager.&#34;&#34;&#34;

    cache_dir: Path

    def __init__(self, cache_dir: Path):
        &#34;&#34;&#34;Instantiate a new Pymc3CacheManager object.

        Args:
            cache_dir (Path): The directory for caching sampling/fitting results.
        &#34;&#34;&#34;
        self.cache_dir = cache_dir
        _mkdir(self.cache_dir)

    def get_cache_file_names(self) -&gt; ModelComponentCachePaths:
        &#34;&#34;&#34;Generate standard caching file paths.

        Raises:
            ValueError: Thrown if `self.cache_dir` is None.

        Returns:
            ModelComponentCachePaths: Object containing the paths to use for caching
              various results from fitting a model.
        &#34;&#34;&#34;
        if self.cache_dir is None:
            raise ValueError(
                &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
            )
        trace_dir_path = self.cache_dir / &#34;pm-trace&#34;
        prior_file_path = self.cache_dir / &#34;prior-predictive-check.pkl&#34;
        post_file_path = self.cache_dir / &#34;posterior-predictive-check.pkl&#34;
        approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
        return ModelComponentCachePaths(
            trace_path=trace_dir_path,
            prior_predictive_path=prior_file_path,
            posterior_predictive_path=post_file_path,
            approximation_path=approx_file_path,
        )

    def read_cached_sampling(self, model: pm.Model) -&gt; pmapi.MCMCSamplingResults:
        &#34;&#34;&#34;Read sampling from cache.

        Args:
            model (pm.Model): The model corresponding to the cached sampling.

        Returns:
            pmapi.MCMCSamplingResults: The cached data.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()

        trace = pm.load_trace(cache_paths.trace_path.as_posix(), model=model)
        post_check = _get_pickle(cache_paths.posterior_predictive_path)
        prior_check = _get_pickle(cache_paths.prior_predictive_path)

        return pmapi.MCMCSamplingResults(
            trace=trace, prior_predictive=prior_check, posterior_predictive=post_check
        )

    def read_cached_approximation(
        self, draws: int = 1000
    ) -&gt; pmapi.ApproximationSamplingResults:
        &#34;&#34;&#34;Read VI Approximation results from cache.

        Args:
            draws (int, optional): The number of draws from the trace. Default is 1000.

        Returns:
            pmapi.ApproximationSamplingResults: The cached data.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()

        post_check = _get_pickle(cache_paths.posterior_predictive_path)
        prior_check = _get_pickle(cache_paths.prior_predictive_path)
        approx = _get_pickle(cache_paths.approximation_path)
        trace = approx.sample(draws)

        return pmapi.ApproximationSamplingResults(
            trace=trace,
            prior_predictive=prior_check,
            posterior_predictive=post_check,
            approximation=approx,
        )

    def cache_sampling_results(
        self, res: Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]
    ) -&gt; None:
        &#34;&#34;&#34;Cache sampling results to disk.

        Args:
            res (Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]):
              The results to cache.
        &#34;&#34;&#34;
        _mkdir(self.cache_dir)
        cache_paths = self.get_cache_file_names()
        _write_pickle(res.posterior_predictive, cache_paths.posterior_predictive_path)
        _write_pickle(res.prior_predictive, cache_paths.prior_predictive_path)
        if isinstance(res, pmapi.ApproximationSamplingResults):
            _write_pickle(res.approximation, cache_paths.approximation_path)
        elif isinstance(res, pmapi.MCMCSamplingResults):
            pm.save_trace(
                res.trace, directory=cache_paths.trace_path.as_posix(), overwrite=True
            )

    def cache_exists(self, method: str) -&gt; bool:
        &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

        This method checks for each pickle file and the trace directory (if applicable).

        Args:
            method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

        Returns:
            bool: Does the cache exist?

        Raises:
            ValueError: If the passed method is not an acceptable option.
        &#34;&#34;&#34;
        cache_paths = self.get_cache_file_names()
        if (
            not cache_paths.prior_predictive_path.exists()
            or not cache_paths.posterior_predictive_path
        ):
            return False

        if method == &#34;mcmc&#34;:
            return cache_paths.trace_path.exists()
        elif method == &#34;approx&#34;:
            return cache_paths.approximation_path.exists()
        else:
            raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)

    def clear_cache(self) -&gt; bool:
        &#34;&#34;&#34;Remove the cache directory.

        Returns:
            bool: Whether the directory was removed or not. Returns False if the
              directory did not exist.
        &#34;&#34;&#34;
        if self.cache_dir.exists():
            shutil.rmtree(self.cache_dir)
            return True
        return False</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.managers.cache_managers.Pymc3CacheManager.cache_exists"><code class="name flex">
<span>def <span class="ident">cache_exists</span></span>(<span>self, method: str) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Confirm that the cached sampling/fitting results exist.</p>
<p>This method checks for each pickle file and the trace directory (if applicable).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Which cache to look for (either "mcmc" or "approx").</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Does the cache exist?</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the passed method is not an acceptable option.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cache_exists(self, method: str) -&gt; bool:
    &#34;&#34;&#34;Confirm that the cached sampling/fitting results exist.

    This method checks for each pickle file and the trace directory (if applicable).

    Args:
        method (str): Which cache to look for (either &#34;mcmc&#34; or &#34;approx&#34;).

    Returns:
        bool: Does the cache exist?

    Raises:
        ValueError: If the passed method is not an acceptable option.
    &#34;&#34;&#34;
    cache_paths = self.get_cache_file_names()
    if (
        not cache_paths.prior_predictive_path.exists()
        or not cache_paths.posterior_predictive_path
    ):
        return False

    if method == &#34;mcmc&#34;:
        return cache_paths.trace_path.exists()
    elif method == &#34;approx&#34;:
        return cache_paths.approximation_path.exists()
    else:
        raise ValueError(f&#34;Unknown method &#39;{method}&#39;.&#34;)</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager.cache_sampling_results"><code class="name flex">
<span>def <span class="ident">cache_sampling_results</span></span>(<span>self, res: Union[src.modeling.pymc3_sampling_api.MCMCSamplingResults, src.modeling.pymc3_sampling_api.ApproximationSamplingResults]) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Cache sampling results to disk.</p>
<h2 id="args">Args</h2>
<p>res (Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]):
The results to cache.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cache_sampling_results(
    self, res: Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]
) -&gt; None:
    &#34;&#34;&#34;Cache sampling results to disk.

    Args:
        res (Union[pmapi.MCMCSamplingResults, pmapi.ApproximationSamplingResults]):
          The results to cache.
    &#34;&#34;&#34;
    _mkdir(self.cache_dir)
    cache_paths = self.get_cache_file_names()
    _write_pickle(res.posterior_predictive, cache_paths.posterior_predictive_path)
    _write_pickle(res.prior_predictive, cache_paths.prior_predictive_path)
    if isinstance(res, pmapi.ApproximationSamplingResults):
        _write_pickle(res.approximation, cache_paths.approximation_path)
    elif isinstance(res, pmapi.MCMCSamplingResults):
        pm.save_trace(
            res.trace, directory=cache_paths.trace_path.as_posix(), overwrite=True
        )</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager.clear_cache"><code class="name flex">
<span>def <span class="ident">clear_cache</span></span>(<span>self) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the cache directory.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether the directory was removed or not. Returns False if the
directory did not exist.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_cache(self) -&gt; bool:
    &#34;&#34;&#34;Remove the cache directory.

    Returns:
        bool: Whether the directory was removed or not. Returns False if the
          directory did not exist.
    &#34;&#34;&#34;
    if self.cache_dir.exists():
        shutil.rmtree(self.cache_dir)
        return True
    return False</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager.get_cache_file_names"><code class="name flex">
<span>def <span class="ident">get_cache_file_names</span></span>(<span>self) -> <a title="src.managers.cache_managers.ModelComponentCachePaths" href="#src.managers.cache_managers.ModelComponentCachePaths">ModelComponentCachePaths</a></span>
</code></dt>
<dd>
<div class="desc"><p>Generate standard caching file paths.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>Thrown if <code>self.cache_dir</code> is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="src.managers.cache_managers.ModelComponentCachePaths" href="#src.managers.cache_managers.ModelComponentCachePaths">ModelComponentCachePaths</a></code></dt>
<dd>Object containing the paths to use for caching
various results from fitting a model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cache_file_names(self) -&gt; ModelComponentCachePaths:
    &#34;&#34;&#34;Generate standard caching file paths.

    Raises:
        ValueError: Thrown if `self.cache_dir` is None.

    Returns:
        ModelComponentCachePaths: Object containing the paths to use for caching
          various results from fitting a model.
    &#34;&#34;&#34;
    if self.cache_dir is None:
        raise ValueError(
            &#34;Cannot generate caching directory when `cache_dir` is None.&#34;
        )
    trace_dir_path = self.cache_dir / &#34;pm-trace&#34;
    prior_file_path = self.cache_dir / &#34;prior-predictive-check.pkl&#34;
    post_file_path = self.cache_dir / &#34;posterior-predictive-check.pkl&#34;
    approx_file_path = self.cache_dir / &#34;vi-approximation.pkl&#34;
    return ModelComponentCachePaths(
        trace_path=trace_dir_path,
        prior_predictive_path=prior_file_path,
        posterior_predictive_path=post_file_path,
        approximation_path=approx_file_path,
    )</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager.read_cached_approximation"><code class="name flex">
<span>def <span class="ident">read_cached_approximation</span></span>(<span>self, draws: int = 1000) -> <a title="src.modeling.pymc3_sampling_api.ApproximationSamplingResults" href="../modeling/pymc3_sampling_api.html#src.modeling.pymc3_sampling_api.ApproximationSamplingResults">ApproximationSamplingResults</a></span>
</code></dt>
<dd>
<div class="desc"><p>Read VI Approximation results from cache.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>draws</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of draws from the trace. Default is 1000.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pmapi.ApproximationSamplingResults</code></dt>
<dd>The cached data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_cached_approximation(
    self, draws: int = 1000
) -&gt; pmapi.ApproximationSamplingResults:
    &#34;&#34;&#34;Read VI Approximation results from cache.

    Args:
        draws (int, optional): The number of draws from the trace. Default is 1000.

    Returns:
        pmapi.ApproximationSamplingResults: The cached data.
    &#34;&#34;&#34;
    cache_paths = self.get_cache_file_names()

    post_check = _get_pickle(cache_paths.posterior_predictive_path)
    prior_check = _get_pickle(cache_paths.prior_predictive_path)
    approx = _get_pickle(cache_paths.approximation_path)
    trace = approx.sample(draws)

    return pmapi.ApproximationSamplingResults(
        trace=trace,
        prior_predictive=prior_check,
        posterior_predictive=post_check,
        approximation=approx,
    )</code></pre>
</details>
</dd>
<dt id="src.managers.cache_managers.Pymc3CacheManager.read_cached_sampling"><code class="name flex">
<span>def <span class="ident">read_cached_sampling</span></span>(<span>self, model: pymc3.model.Model) -> <a title="src.modeling.pymc3_sampling_api.MCMCSamplingResults" href="../modeling/pymc3_sampling_api.html#src.modeling.pymc3_sampling_api.MCMCSamplingResults">MCMCSamplingResults</a></span>
</code></dt>
<dd>
<div class="desc"><p>Read sampling from cache.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>pm.Model</code></dt>
<dd>The model corresponding to the cached sampling.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pmapi.MCMCSamplingResults</code></dt>
<dd>The cached data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_cached_sampling(self, model: pm.Model) -&gt; pmapi.MCMCSamplingResults:
    &#34;&#34;&#34;Read sampling from cache.

    Args:
        model (pm.Model): The model corresponding to the cached sampling.

    Returns:
        pmapi.MCMCSamplingResults: The cached data.
    &#34;&#34;&#34;
    cache_paths = self.get_cache_file_names()

    trace = pm.load_trace(cache_paths.trace_path.as_posix(), model=model)
    post_check = _get_pickle(cache_paths.posterior_predictive_path)
    prior_check = _get_pickle(cache_paths.prior_predictive_path)

    return pmapi.MCMCSamplingResults(
        trace=trace, prior_predictive=prior_check, posterior_predictive=post_check
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.managers" href="index.html">src.managers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.managers.cache_managers.ArvizCacheManager" href="#src.managers.cache_managers.ArvizCacheManager">ArvizCacheManager</a></code></h4>
<ul class="">
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.cache_exists" href="#src.managers.cache_managers.ArvizCacheManager.cache_exists">cache_exists</a></code></li>
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.cache_sampling_results" href="#src.managers.cache_managers.ArvizCacheManager.cache_sampling_results">cache_sampling_results</a></code></li>
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.clear_cache" href="#src.managers.cache_managers.ArvizCacheManager.clear_cache">clear_cache</a></code></li>
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.get_cache_file_names" href="#src.managers.cache_managers.ArvizCacheManager.get_cache_file_names">get_cache_file_names</a></code></li>
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.read_cached_approximation" href="#src.managers.cache_managers.ArvizCacheManager.read_cached_approximation">read_cached_approximation</a></code></li>
<li><code><a title="src.managers.cache_managers.ArvizCacheManager.read_cached_sampling" href="#src.managers.cache_managers.ArvizCacheManager.read_cached_sampling">read_cached_sampling</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.managers.cache_managers.ArvizCachePaths" href="#src.managers.cache_managers.ArvizCachePaths">ArvizCachePaths</a></code></h4>
</li>
<li>
<h4><code><a title="src.managers.cache_managers.ModelComponentCachePaths" href="#src.managers.cache_managers.ModelComponentCachePaths">ModelComponentCachePaths</a></code></h4>
</li>
<li>
<h4><code><a title="src.managers.cache_managers.Pymc3CacheManager" href="#src.managers.cache_managers.Pymc3CacheManager">Pymc3CacheManager</a></code></h4>
<ul class="">
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.cache_exists" href="#src.managers.cache_managers.Pymc3CacheManager.cache_exists">cache_exists</a></code></li>
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.cache_sampling_results" href="#src.managers.cache_managers.Pymc3CacheManager.cache_sampling_results">cache_sampling_results</a></code></li>
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.clear_cache" href="#src.managers.cache_managers.Pymc3CacheManager.clear_cache">clear_cache</a></code></li>
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.get_cache_file_names" href="#src.managers.cache_managers.Pymc3CacheManager.get_cache_file_names">get_cache_file_names</a></code></li>
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.read_cached_approximation" href="#src.managers.cache_managers.Pymc3CacheManager.read_cached_approximation">read_cached_approximation</a></code></li>
<li><code><a title="src.managers.cache_managers.Pymc3CacheManager.read_cached_sampling" href="#src.managers.cache_managers.Pymc3CacheManager.read_cached_sampling">read_cached_sampling</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>