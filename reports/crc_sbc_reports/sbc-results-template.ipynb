{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "from src.command_line_interfaces import cli_helpers\n",
    "from src.modeling.simulation_based_calibration_helpers import SBCFileManager\n",
    "\n",
    "notebook_tic = time()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "gg.theme_set(gg.theme_classic())\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "RANDOM_SEED = 847\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "pymc3_cache_dir = Path(\"..\", \"models\", \"modeling_cache\", \"pymc3_model_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for papermill:\n",
    "\n",
    "- `MODEL`: which model was tested\n",
    "- `MODEL_NAME`: unique, identifiable name of the model\n",
    "- `SBC_RESULTS_DIR`: directory containing results of many rounds of SBC\n",
    "- `NUM_SIMULATIONS`: the number of simiulations; will be used to check that all results are found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papermill parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL = \"\"\n",
    "MODEL_NAME = \"\"\n",
    "SBC_RESULTS_DIR = \"\"\n",
    "NUM_SIMULATIONS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and validate papermill parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Build the model using the `MODEL` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "ModelClass = cli_helpers.get_model_class(cli_helpers.ModelOption[MODEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Check values passed as the directory with results of the rounds of SBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbc_results_dir = Path(\"../..\", SBC_RESULTS_DIR)\n",
    "assert sbc_results_dir.is_dir()\n",
    "assert sbc_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Confirm that there is a positive number of simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert NUM_SIMULATIONS > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Read in all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_parameter(p: str) -> List[str]:\n",
    "    return [a for a in re.split(\"\\\\[|,|\\\\]\", p) if a != \"\"]\n",
    "\n",
    "\n",
    "def get_prior_value_using_index_list(ary: np.ndarray, idx: List[int]) -> float:\n",
    "    if len(idx) == 0:\n",
    "        return ary\n",
    "\n",
    "    assert len(idx) == len(ary.shape)\n",
    "    value = ary\n",
    "    for i in idx:\n",
    "        value = value[i]\n",
    "    return value\n",
    "\n",
    "\n",
    "def make_priors_dataframe(\n",
    "    priors: Dict[str, np.ndarray], parameters: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\"parameter\": parameters, \"true_value\": 0}).set_index(\"parameter\")\n",
    "    for parameter in parameters:\n",
    "        split_p = split_parameter(parameter)\n",
    "        param = split_p[0]\n",
    "        idx = [int(i) for i in split_p[1:]]\n",
    "        value = get_prior_value_using_index_list(priors[param][0], idx)\n",
    "        df.loc[parameter] = value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulation_posteriors = []\n",
    "\n",
    "for sbc_dir in sbc_results_dir.iterdir():\n",
    "    sbc_fm = SBCFileManager(sbc_dir)\n",
    "    if not sbc_fm.all_data_exists():\n",
    "        raise Exception(f\"Not all output from '{sbc_fm.dir.name}' exist.\")\n",
    "    res = sbc_fm.get_sbc_results()\n",
    "    true_values = make_priors_dataframe(\n",
    "        res.priors, parameters=res.posterior_summary.index.values\n",
    "    )\n",
    "    posterior_summary = res.posterior_summary.merge(\n",
    "        true_values, left_index=True, right_index=True\n",
    "    )\n",
    "    simulation_posteriors.append(posterior_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(simulation_posteriors) == NUM_SIMULATIONS:\n",
    "    print(\"Collected all simulations.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"The number of simluations ({NUM_SIMULATIONS}) does not match the number collected ({len(simulation_posteriors)}).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hdi_colnames_from_az_summary(df: pd.DataFrame) -> Tuple[str, str]:\n",
    "    cols: List[str] = [c for c in df.columns if \"hdi_\" in c]\n",
    "    cols = [c for c in cols if \"%\" in c]\n",
    "    assert len(cols) == 2\n",
    "    return cols[0], cols[1]\n",
    "\n",
    "\n",
    "def is_true_value_within_hdi(\n",
    "    low_hdi: pd.Series, true_vals: pd.Series, high_hdi: pd.Series\n",
    ") -> np.ndarray:\n",
    "    return (\n",
    "        (low_hdi.values < true_vals.values).astype(int)\n",
    "        * (true_vals.values < high_hdi.values).astype(int)\n",
    "    ).astype(bool)\n",
    "\n",
    "\n",
    "def assign_column_for_within_hdi(\n",
    "    df: pd.DataFrame, true_value_col: str = \"true_value\"\n",
    ") -> pd.DataFrame:\n",
    "    hdi_low, hdi_high = get_hdi_colnames_from_az_summary(df)\n",
    "    df[\"within_hdi\"] = is_true_value_within_hdi(\n",
    "        df[hdi_low], df[\"true_value\"], df[hdi_high]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def measure_posterior_accuracy(df: pd.DataFrame) -> float:\n",
    "    return assign_column_for_within_hdi(df)[\"within_hdi\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdi_acc = [measure_posterior_accuracy(p) for p in simulation_posteriors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(hdi_acc, ax=ax)\n",
    "ax.set_xlabel(\"HDI accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_posteriors_df = pd.concat(\n",
    "    [\n",
    "        d.assign(simulation_id=f\"sim_id_{str(i).rjust(4, '0')}\")\n",
    "        for i, d in enumerate(simulation_posteriors)\n",
    "    ]\n",
    ")\n",
    "simulation_posteriors_df[\"parameter_name\"] = [\n",
    "    x.split(\"[\")[0] for x in simulation_posteriors_df.index.values\n",
    "]\n",
    "simulation_posteriors_df = simulation_posteriors_df.set_index(\n",
    "    \"parameter_name\", append=True\n",
    ").pipe(assign_column_for_within_hdi)\n",
    "\n",
    "simulation_posteriors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_parameter = (\n",
    "    simulation_posteriors_df.copy()\n",
    "    .groupby([\"parameter_name\"])[\"within_hdi\"]\n",
    "    .mean()\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values(\"within_hdi\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "accuracy_per_parameter[\"parameter_name\"] = pd.Categorical(\n",
    "    accuracy_per_parameter[\"parameter_name\"],\n",
    "    categories=accuracy_per_parameter[\"parameter_name\"].values,\n",
    ")\n",
    "\n",
    "(\n",
    "    gg.ggplot(accuracy_per_parameter, gg.aes(x=\"parameter_name\", y=\"within_hdi\"))\n",
    "    + gg.geom_col()\n",
    "    + gg.scale_y_continuous(expand=(0, 0, 0.02, 0))\n",
    "    + gg.labs(\n",
    "        x=\"parameter\",\n",
    "        y=\"freq. of true value in 89% HDI\",\n",
    "        title=\"Average accuracy of each parameter\",\n",
    "    )\n",
    "    + gg.theme(axis_ticks_major_x=gg.element_blank(), figure_size=(6, 4))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_low, hdi_high = get_hdi_colnames_from_az_summary(simulation_posteriors_df)\n",
    "\n",
    "(\n",
    "    gg.ggplot(\n",
    "        simulation_posteriors_df.reset_index(drop=False).query(\"parameter_name != 'μ'\"),\n",
    "        gg.aes(x=\"true_value\", y=\"mean\", color=\"within_hdi\"),\n",
    "    )\n",
    "    + gg.facet_wrap(\"~ parameter_name\", ncol=3, scales=\"free\")\n",
    "    + gg.geom_linerange(gg.aes(ymin=hdi_low, ymax=hdi_high), alpha=0.2, size=0.2)\n",
    "    + gg.geom_point(size=0.3, alpha=0.3)\n",
    "    + gg.geom_abline(slope=1, intercept=0, linetype=\"--\")\n",
    "    + gg.scale_color_brewer(\n",
    "        type=\"qual\",\n",
    "        palette=\"Set1\",\n",
    "        labels=(\"outside\", \"inside\"),\n",
    "        guide=gg.guide_legend(\n",
    "            title=\"within HDI\",\n",
    "            override_aes={\"alpha\": 1, \"size\": 1},\n",
    "        ),\n",
    "    )\n",
    "    + gg.theme(\n",
    "        figure_size=(10, 20),\n",
    "        strip_background=gg.element_blank(),\n",
    "        strip_text=gg.element_text(face=\"bold\"),\n",
    "        panel_spacing=0.25,\n",
    "    )\n",
    "    + gg.labs(\n",
    "        x=\"true value\",\n",
    "        y=\"mean of posterior\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_toc = time()\n",
    "print(f\"execution time: {(notebook_toc - notebook_tic) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -u -v -iv -b -h -m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
