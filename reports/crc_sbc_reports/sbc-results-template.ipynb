{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model SBC Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "import janitor  # noqa: F401\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "\n",
    "from src.analysis import pymc3_analysis as pmanal\n",
    "from src.analysis import sbc_analysis as sbcanal\n",
    "from src.loggers import set_console_handler_level\n",
    "from src.managers.model_cache_managers import Pymc3ModelCacheManager\n",
    "from src.modeling import simulation_based_calibration_helpers as sbc\n",
    "from src.project_enums import ModelFitMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_tic = time()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "gg.theme_set(gg.theme_classic())\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "RANDOM_SEED = 847\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "set_console_handler_level(logging.WARNING)\n",
    "pymc3_cache_dir = Path(\"..\", \"models\", \"modeling_cache\", \"pymc3_model_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for papermill:\n",
    "\n",
    "- `MODEL_NAME`: unique, identifiable name of the model\n",
    "- `SBC_RESULTS_DIR`: directory containing results of many rounds of SBC\n",
    "- `SBC_COLLATED_RESULTS`: path to collated simulation posteriors\n",
    "- `SBC_UNIFORMITY_RESULTS`: path to results of the uniformity test\n",
    "- `NUM_SIMULATIONS`: the number of simiulations; will be used to check that all results are found\n",
    "- `CONFIG_PATH`: path to the model configuration file\n",
    "- `FIT_METHOD`: model fitting method used for this SBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papermill parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"\"\n",
    "SBC_RESULTS_DIR = \"\"\n",
    "SBC_COLLATED_RESULTS = \"\"\n",
    "SBC_UNIFORMITY_RESULTS = \"\"\n",
    "NUM_SIMULATIONS = -1\n",
    "CONFIG_PATH = \"\"\n",
    "FIT_METHOD_STR = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and validate papermill parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Check values passed as the directory with results of the rounds of SBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_addition = \"../..\"\n",
    "\n",
    "sbc_results_dir = Path(path_addition, SBC_RESULTS_DIR)\n",
    "assert sbc_results_dir.is_dir()\n",
    "assert sbc_results_dir.exists()\n",
    "\n",
    "sbc_collated_results_path = Path(path_addition, SBC_COLLATED_RESULTS)\n",
    "assert sbc_collated_results_path.is_file()\n",
    "assert sbc_collated_results_path.exists()\n",
    "\n",
    "sbc_uniformity_results_path = Path(path_addition, SBC_UNIFORMITY_RESULTS)\n",
    "assert sbc_uniformity_results_path.is_file()\n",
    "assert sbc_uniformity_results_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Confirm that there is a positive number of simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert NUM_SIMULATIONS > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT_METHOD = ModelFitMethod(FIT_METHOD_STR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Read in all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior summaries dataframe.\n",
    "simulation_posteriors_df = pd.read_pickle(sbc_collated_results_path)\n",
    "simulation_posteriors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformity test results dataframe.\n",
    "sbc_uniformity_test = pd.read_pickle(sbc_uniformity_results_path)\n",
    "var_names = sbc_uniformity_test.parameter.tolist()\n",
    "parameter_names = [x.split(\"[\")[0] for x in var_names]\n",
    "sbc_uniformity_test[\"parameter_name\"] = parameter_names\n",
    "sbc_uniformity_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbc_analyzer = sbcanal.SBCAnalysis(\n",
    "    root_dir=sbc_results_dir,\n",
    "    pattern=\"perm\",\n",
    "    n_simulations=NUM_SIMULATIONS,\n",
    "    simulation_posteriors=simulation_posteriors_df,\n",
    "    uniformity_test_results=sbc_uniformity_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADVI approximation histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_METHOD is ModelFitMethod.ADVI:\n",
    "    advi_histories: list[np.ndarray] = []\n",
    "\n",
    "    for dir in sbc_results_dir.iterdir():\n",
    "        if not dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        cache_manager = Pymc3ModelCacheManager(name=MODEL_NAME, root_cache_dir=dir)\n",
    "        if cache_manager.advi_cache_exists():\n",
    "            _, advi_approx = cache_manager.get_advi_cache()\n",
    "            advi_histories.append(advi_approx.hist)\n",
    "    n_sims_advi_hist = min(NUM_SIMULATIONS, 5)\n",
    "    sample_hist_idxs = np.random.choice(\n",
    "        list(range(len(advi_histories))), size=n_sims_advi_hist, replace=False\n",
    "    )\n",
    "\n",
    "    def make_hist_df(sim_idx: int, hist_list: list[np.ndarray]) -> pd.DataFrame:\n",
    "        df = pd.DataFrame({\"sim_idx\": sim_idx, \"loss\": hist_list[sim_idx].flatten()})\n",
    "        df[\"step\"] = np.arange(df.shape[0])\n",
    "        return df\n",
    "\n",
    "    sampled_advi_histories = pd.concat(\n",
    "        [make_hist_df(i, advi_histories) for i in sample_hist_idxs]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    (\n",
    "        gg.ggplot(\n",
    "            sampled_advi_histories,\n",
    "            gg.aes(x=\"step\", y=\"np.log(loss)\", color=\"factor(sim_idx)\"),\n",
    "        )\n",
    "        + gg.geom_line(alpha=0.5)\n",
    "        + gg.scale_color_brewer(type=\"qual\", palette=\"Set1\")\n",
    "        + gg.scale_x_continuous(expand=(0, 0))\n",
    "        + gg.scale_y_continuous(expand=(0.01, 0, 0.02, 0))\n",
    "        + gg.theme(legend_position=(0.8, 0.5))\n",
    "        + gg.labs(y=\"log loss\", color=\"sim. idx.\")\n",
    "    ).draw()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncompleteCachedResultsWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "\n",
    "if FIT_METHOD is ModelFitMethod.MCMC:\n",
    "    pprint(sbc_analyzer.mcmc_diagnostics())\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    all_sbc_perm_dirs = list(sbc_results_dir.iterdir())\n",
    "    for perm_dir in np.random.choice(\n",
    "        all_sbc_perm_dirs, size=min([5, len(all_sbc_perm_dirs)]), replace=False\n",
    "    ):\n",
    "        print(perm_dir.name)\n",
    "        print(\"-\" * 30)\n",
    "        sbc_fm = sbc.SBCFileManager(perm_dir)\n",
    "        if sbc_fm.all_data_exists():\n",
    "            sbc_res = sbc_fm.get_sbc_results()\n",
    "            _ = pmanal.describe_mcmc(sbc_res.inference_obj)\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                \"Cannot find all components of the SBC results.\",\n",
    "                IncompleteCachedResultsWarning,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_parameter = sbc_analyzer.run_posterior_accuracy_test()\n",
    "\n",
    "accuracy_per_parameter[\"parameter_name\"] = pd.Categorical(\n",
    "    accuracy_per_parameter[\"parameter_name\"],\n",
    "    categories=accuracy_per_parameter[\"parameter_name\"].values,\n",
    ")\n",
    "\n",
    "(\n",
    "    gg.ggplot(accuracy_per_parameter, gg.aes(x=\"parameter_name\", y=\"within_hdi\"))\n",
    "    + gg.geom_col()\n",
    "    + gg.scale_y_continuous(expand=(0, 0, 0.02, 0))\n",
    "    + gg.labs(\n",
    "        x=\"parameter\",\n",
    "        y=\"freq. of true value in 89% HDI\",\n",
    "        title=\"Average accuracy of each parameter\",\n",
    "    )\n",
    "    + gg.theme(axis_ticks_major_x=gg.element_blank(), figure_size=(6, 4))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_low, hdi_high = pmanal.get_hdi_colnames_from_az_summary(simulation_posteriors_df)\n",
    "\n",
    "\n",
    "def filter_uninsteresting_parameters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.reset_index(drop=False)\n",
    "        .query(\"parameter_name != 'μ'\")\n",
    "        .filter_string(\"parameter_name\", search_string=\"offset\", complement=True)\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    gg.ggplot(\n",
    "        filter_uninsteresting_parameters(simulation_posteriors_df),\n",
    "        gg.aes(x=\"true_value\", y=\"mean\", color=\"within_hdi\"),\n",
    "    )\n",
    "    + gg.facet_wrap(\"~ parameter_name\", ncol=3, scales=\"free\")\n",
    "    + gg.geom_linerange(gg.aes(ymin=hdi_low, ymax=hdi_high), alpha=0.2, size=0.2)\n",
    "    + gg.geom_point(size=0.3, alpha=0.3)\n",
    "    + gg.geom_abline(slope=1, intercept=0, linetype=\"--\")\n",
    "    + gg.scale_color_brewer(\n",
    "        type=\"qual\",\n",
    "        palette=\"Set1\",\n",
    "        labels=(\"outside\", \"inside\"),\n",
    "        guide=gg.guide_legend(\n",
    "            title=\"within HDI\",\n",
    "            override_aes={\"alpha\": 1, \"size\": 1},\n",
    "        ),\n",
    "    )\n",
    "    + gg.theme(\n",
    "        figure_size=(10, 20),\n",
    "        strip_background=gg.element_blank(),\n",
    "        strip_text=gg.element_text(face=\"bold\"),\n",
    "        panel_spacing=0.25,\n",
    "    )\n",
    "    + gg.labs(\n",
    "        x=\"true value\",\n",
    "        y=\"mean of posterior\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### SBC Uniformity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_to_plot = (\n",
    "    sbc_uniformity_test[[\"parameter\", \"parameter_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values([\"parameter_name\", \"parameter\"])\n",
    "    .groupby(\"parameter_name\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    "    .parameter.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "for v in var_names_to_plot:\n",
    "    ax = sbc_analyzer.plot_uniformity(sbc_uniformity_test.query(f\"parameter == '{v}'\"))\n",
    "    ax.set_title(v)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_toc = time()\n",
    "print(f\"execution time: {(notebook_toc - notebook_tic) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -u -v -iv -b -h -m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
