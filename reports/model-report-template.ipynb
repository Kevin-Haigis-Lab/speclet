{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import pymc3 as pm\n",
    "from analysis import color_pal as pal\n",
    "from analysis import common_data_processing as dphelp\n",
    "from analysis import pymc3_analysis as pmanal\n",
    "from analysis import pymc3_sampling_api as pmapi\n",
    "from analysis import sampling_pymc3_models as sampling\n",
    "from analysis.context_managers import set_directory\n",
    "from analysis.pymc3_models import crc_models\n",
    "\n",
    "notebook_tic = time()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "gg.theme_set(gg.theme_classic())\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "RANDOM_SEED = 847\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "pymc3_cache_dir = Path(\"pymc3_model_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for papermill:\n",
    "\n",
    "- `MODEL`: which model was tested\n",
    "- `MODEL_NAME`: name of the model\n",
    "- `DEBUG`: if in debug mode or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papermill parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL = \"crc-m1\"\n",
    "MODEL_NAME = \"CRC-model1\"\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache_dir = sampling.make_cache_name(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with set_directory(\"..\"):\n",
    "    model, _, data = sampling.main(\n",
    "        model=MODEL, name=MODEL_NAME, sample=False, debug=DEBUG, random_seed=RANDOM_SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cached model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = pmapi.read_cached_vi(model_cache_dir)\n",
    "\n",
    "model_az = az.from_pymc3(\n",
    "    trace=model_res[\"trace\"],\n",
    "    model=model,\n",
    "    posterior_predictive=model_res[\"posterior_predictive\"],\n",
    "    prior=model_res[\"prior_predictive\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmanal.plot_vi_hist(model_res[\"approximation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape(trace: np.ndarray) -> np.ndarray:\n",
    "    if len(trace.shape) == 1:\n",
    "        return trace[:, None]\n",
    "    return trace\n",
    "\n",
    "\n",
    "def add_hdi(p: gg.ggplot, values: np.ndarray, color: str) -> gg.ggplot:\n",
    "    m = np.mean(values)\n",
    "    hdi = az.hdi(values, hdi_prob=0.89).flatten()\n",
    "    p = (\n",
    "        p\n",
    "        + gg.geom_vline(xintercept=m, color=color)\n",
    "        + gg.geom_vline(xintercept=hdi, color=color, linetype=\"--\")\n",
    "    )\n",
    "    return p\n",
    "\n",
    "\n",
    "def variable_distribution_plot(var, trace: np.ndarray, max_plot=20000) -> gg.ggplot:\n",
    "    trace = check_shape(trace)\n",
    "\n",
    "    # Sample 25% of the trace.\n",
    "    d = pd.DataFrame(trace).melt().assign(variable=lambda d: d.variable.astype(\"str\"))\n",
    "    d_summaries = d.groupby([\"variable\"])[\"value\"].mean().reset_index(drop=False)\n",
    "\n",
    "    if d.shape[0] > max_plot:\n",
    "        d = d.sample(n=max_plot)\n",
    "    else:\n",
    "        d = d.sample(frac=0.2)\n",
    "\n",
    "    p = (\n",
    "        gg.ggplot(d, gg.aes(x=\"value\"))\n",
    "        + gg.geom_density(alpha=0.1)\n",
    "        + gg.geom_vline(xintercept=0, color=\"black\", size=0.7, alpha=0.7, linetype=\"--\")\n",
    "        + gg.scale_x_continuous(expand=(0, 0))\n",
    "        + gg.scale_y_continuous(expand=(0, 0, 0.02, 0))\n",
    "        + gg.theme(legend_position=\"none\", figure_size=(6.5, 3))\n",
    "        + gg.labs(x=\"posterior\", y=\"density\", title=f\"Posterior distirbution of {var}\")\n",
    "    )\n",
    "\n",
    "    c = pal.sns_blue\n",
    "\n",
    "    if len(d_summaries) > 1:\n",
    "        p = p + gg.geom_rug(\n",
    "            data=d_summaries, sides=\"b\", alpha=0.5, color=c, length=0.08\n",
    "        )\n",
    "    else:\n",
    "        p = add_hdi(p, trace.flatten(), color=c)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_inspect = model_res[\"trace\"].varnames\n",
    "vars_to_inspect = [v for v in vars_to_inspect if not \"log\" in v]\n",
    "vars_to_inspect.sort()\n",
    "\n",
    "for var in vars_to_inspect:\n",
    "    trace = model_res[\"trace\"][var]\n",
    "    if len(trace.shape) > 1 and trace.shape[1] == data.shape[0]:\n",
    "        # Do not plot the final deterministic mean (usually \"Î¼\").\n",
    "        continue\n",
    "    print(variable_distribution_plot(var, model_res[\"trace\"][var]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_res[\"posterior_predictive\"]\n",
    "pred_summary = pmanal.summarize_posterior_predictions(\n",
    "    predictions[\"lfc\"],\n",
    "    merge_with=data[[\"lfc\", \"depmap_id\", \"hugo_symbol\", \"sgrna\", \"log2_cn\"]],\n",
    ")\n",
    "pred_summary[\"error\"] = pred_summary.lfc - pred_summary.pred_mean\n",
    "pred_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_loo_pit(model_az, y=\"lfc\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gg.ggplot(pred_summary, gg.aes(x=\"lfc\", y=\"pred_mean\"))\n",
    "    + gg.geom_hline(yintercept=0, size=0.5, alpha=0.7)\n",
    "    + gg.geom_vline(xintercept=0, size=0.5, alpha=0.7)\n",
    "    + gg.geom_point(size=0.1, alpha=0.2)\n",
    "    + gg.geom_abline(slope=1, intercept=0, size=1, alpha=0.7, color=\"grey\")\n",
    "    + gg.geom_smooth(method=\"glm\", color=pal.sns_red, size=1, alpha=0.7, se=False)\n",
    "    + gg.labs(x=\"observed LFC\", y=\"prediticed LFC (posterior avg.)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gg.ggplot(pred_summary, gg.aes(x=\"lfc\", y=\"error\"))\n",
    "    + gg.geom_hline(yintercept=0, size=0.5, alpha=0.7)\n",
    "    + gg.geom_vline(xintercept=0, size=0.5, alpha=0.7)\n",
    "    + gg.geom_point(size=0.1, alpha=0.2)\n",
    "    + gg.labs(x=\"observed LFC\", y=\"prediction error\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_error = (\n",
    "    pred_summary.groupby([\"hugo_symbol\"])[\"error\"]\n",
    "    .agg([np.mean, np.std])\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values([\"mean\"])\n",
    "    .reset_index(drop=True)\n",
    "    .assign(\n",
    "        hugo_symbol=lambda d: pd.Categorical(\n",
    "            d.hugo_symbol.astype(str),\n",
    "            categories=d.hugo_symbol.astype(str),\n",
    "            ordered=True,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "n_genes = 15\n",
    "\n",
    "(\n",
    "    gg.ggplot(\n",
    "        gene_error.iloc[list(range(n_genes)) + list(range(-n_genes, -1))],\n",
    "        gg.aes(x=\"hugo_symbol\", y=\"mean\"),\n",
    "    )\n",
    "    + gg.geom_col()\n",
    "    + gg.theme(axis_text_x=gg.element_text(angle=90))\n",
    "    + gg.labs(x=\"gene\", y=\"error\", title=\"Genes with the highest average error\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gg.ggplot(pred_summary, gg.aes(x=\"log2_cn\", y=\"error\"))\n",
    "    + gg.geom_hline(yintercept=0, size=0.5, alpha=0.7, linetype=\"--\")\n",
    "    + gg.geom_vline(xintercept=0, size=0.5, alpha=0.7, linetype=\"--\")\n",
    "    + gg.geom_point(size=0.1, alpha=0.2)\n",
    "    + gg.labs(x=\"gene copy number (log2)\", y=\"predition error\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_toc = time()\n",
    "print(f\"execution time: {(notebook_toc - notebook_tic) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -u -v -iv -b -h -m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
